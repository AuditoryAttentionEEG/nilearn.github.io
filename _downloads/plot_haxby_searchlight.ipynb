{
  "nbformat_minor": 0, 
  "nbformat": 4, 
  "cells": [
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "%matplotlib inline"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "\nSearchlight analysis of face vs house recognition\n==================================================\n\nSearchlight analysis requires fitting a classifier a large amount of\ntimes. As a result, it is an intrinsically slow method. In order to speed\nup computing, in this example, Searchlight is run only on one slice on\nthe fMRI (see the generated figures).\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "source": [
        "Load Haxby dataset\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "import numpy as np\nimport nibabel\nfrom nilearn import datasets\nfrom nilearn.image import new_img_like\n\nhaxby_dataset = datasets.fetch_haxby_simple()\n\n# print basic information on the dataset\nprint('Anatomical nifti image (3D) is located at: %s' % haxby_dataset.mask)\nprint('Functional nifti image (4D) is located at: %s' % haxby_dataset.func[0])\n\nfmri_filename = haxby_dataset.func[0]\nfmri_img = nibabel.load(fmri_filename)\ny, session = np.loadtxt(haxby_dataset.session_target[0]).astype('int').T\nconditions = np.recfromtxt(haxby_dataset.conditions_target[0])['f0']"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Restrict to faces and houses\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "from nilearn.image import index_img\ncondition_mask = np.logical_or(conditions == b'face', conditions == b'house')\n\nfmri_img = index_img(fmri_img, condition_mask)\ny, session = y[condition_mask], session[condition_mask]\nconditions = conditions[condition_mask]"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Prepare masks\n\n- mask_img is the original mask\n- process_mask_img is a subset of mask_img, it contains the voxels that\n  should be processed (we only keep the slice z = 26 and the back of the\n  brain to speed up computation)\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "mask_img = nibabel.load(haxby_dataset.mask)\n\n# .astype() makes a copy.\nprocess_mask = mask_img.get_data().astype(np.int)\npicked_slice = 27\nprocess_mask[..., (picked_slice + 1):] = 0\nprocess_mask[..., :picked_slice] = 0\nprocess_mask[:, 30:] = 0\nprocess_mask_img = new_img_like(mask_img, process_mask)"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Searchlight computation\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "# Make processing parallel\n# /!\\ As each thread will print its progress, n_jobs > 1 could mess up the\n#     information output.\nn_jobs = 1\n\n# Define the cross-validation scheme used for validation.\n# Here we use a KFold cross-validation on the session, which corresponds to\n# splitting the samples in 4 folds and make 4 runs using each fold as a test\n# set once and the others as learning sets\nfrom sklearn.cross_validation import KFold\ncv = KFold(y.size, n_folds=4)\n\nimport nilearn.decoding\n# The radius is the one of the Searchlight sphere that will scan the volume\nsearchlight = nilearn.decoding.SearchLight(\n    mask_img,\n    process_mask_img=process_mask_img,\n    radius=5.6, n_jobs=n_jobs,\n    verbose=1, cv=cv)\nsearchlight.fit(fmri_img, y)"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "F-scores computation\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "from nilearn.input_data import NiftiMasker\n\n# For decoding, standardizing is often very important\nnifti_masker = NiftiMasker(mask_img=mask_img, sessions=session,\n                           standardize=True, memory='nilearn_cache',\n                           memory_level=1)\nfmri_masked = nifti_masker.fit_transform(fmri_img)\n\nfrom sklearn.feature_selection import f_classif\nf_values, p_values = f_classif(fmri_masked, y)\np_values = -np.log10(p_values)\np_values[p_values > 10] = 10\np_unmasked = nifti_masker.inverse_transform(p_values).get_data()"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Visualization\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "# Use the fmri mean image as a surrogate of anatomical data\nfrom nilearn import image\nmean_fmri = image.mean_img(fmri_img)\n\nfrom nilearn.plotting import plot_stat_map, show\nplot_stat_map(new_img_like(mean_fmri, searchlight.scores_), mean_fmri,\n              title=\"Searchlight\", display_mode=\"z\", cut_coords=[-16],\n              colorbar=False)\n\n# F_score results\np_ma = np.ma.array(p_unmasked, mask=np.logical_not(process_mask))\nplot_stat_map(new_img_like(mean_fmri, p_ma), mean_fmri,\n              title=\"F-scores\", display_mode=\"z\",\n              cut_coords=[-16], colorbar=False)\n\nshow()"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }
  ], 
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2", 
      "name": "python2", 
      "language": "python"
    }, 
    "language_info": {
      "mimetype": "text/x-python", 
      "nbconvert_exporter": "python", 
      "name": "python", 
      "file_extension": ".py", 
      "version": "2.7.10", 
      "pygments_lexer": "ipython2", 
      "codemirror_mode": {
        "version": 2, 
        "name": "ipython"
      }
    }
  }
}