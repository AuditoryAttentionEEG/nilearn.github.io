

.. _sphx_glr_auto_examples_connectivity_plot_compare_resting_state_decomposition.py:


Dictionary Learning and ICA for doing group analysis of resting-state fMRI
==========================================================================

This example applies dictionary learning and ICA to resting-state data,
visualizing resulting components using atlas plotting tools.

Dictionary learning is a sparsity based decomposition method for extracting
spatial maps. It extracts maps that are naturally sparse and usually cleaner
than ICA

    * Gael Varoquaux et al.
      Multi-subject dictionary learning to segment an atlas of brain spontaneous
      activity
      Information Processing in Medical Imaging, 2011, pp. 562-573, Lecture Notes
      in Computer Science

Available on https://hal.inria.fr/inria-00588898/en/

Load ADHD rest dataset


.. code-block:: python

    from nilearn import datasets

    adhd_dataset = datasets.fetch_adhd(n_subjects=30)
    func_filenames = adhd_dataset.func  # list of 4D nifti files for each subject

    # print basic information on the dataset
    print('First functional nifti image (4D) is at: %s' %
          adhd_dataset.func[0])  # 4D data




.. rst-class:: sphx-glr-horizontal



.. rst-class:: sphx-glr-script-out

 **Output**:


  ::

    First functional nifti image (4D) is at: /home/varoquau/nilearn_data/adhd/data/0010042/0010042_rest_tshift_RPI_voreg_mni.nii.gz


Create two decomposition estimators


.. code-block:: python

    from nilearn.decomposition import DictLearning, CanICA

    n_components = 40




.. rst-class:: sphx-glr-horizontal





Dictionary learning


.. code-block:: python

    dict_learning = DictLearning(n_components=n_components,
                                 memory="nilearn_cache", memory_level=2,
                                 verbose=1,
                                 random_state=0,
                                 n_epochs=1)



.. rst-class:: sphx-glr-horizontal





CanICA


.. code-block:: python

    canica = CanICA(n_components=n_components,
                    memory="nilearn_cache", memory_level=2,
                    threshold=3.,
                    n_init=1,
                    verbose=1)




.. rst-class:: sphx-glr-horizontal





Fit both estimators


.. code-block:: python

    estimators = [dict_learning, canica]
    names = {dict_learning: 'DictionaryLearning', canica: 'CanICA'}
    components_imgs = []

    for estimator in estimators:
        print('[Example] Learning maps using %s model' % names[estimator])
        estimator.fit(func_filenames)
        print('[Example] Saving results')
        # Decomposition estimator embeds their own masker
        masker = estimator.masker_
        # Drop output maps to a Nifti   file
        components_img = masker.inverse_transform(estimator.components_)
        components_img.to_filename('%s_resting_state.nii.gz' %
                                   names[estimator])
        components_imgs.append(components_img)




.. rst-class:: sphx-glr-horizontal



.. rst-class:: sphx-glr-script-out

 **Output**:


  ::

    [Example] Learning maps using DictionaryLearning model
    [MultiNiftiMasker.fit] Loading data from [/home/varoquau/nilearn_data/adhd/data/0010042/0010042_rest_tshift_RPI_voreg_mni.nii.gz, /home/varoquau/nilearn_data/adhd/data/0010064/0010064_rest_tshift_RPI_voreg_mni.nii.gz, /home/varoquau/nilearn_
    [MultiNiftiMasker.fit] Computing mask
    [MultiNiftiMasker.transform] Resampling mask
    [DictLearning] Loading data
    [DictLearning] Learning initial components
    [DictLearning] Computing initial loadings
    [DictLearning] Learning dictionary
    [Example] Saving results
    ________________________________________________________________________________
    [Memory] Calling nilearn.masking.unmask...
    unmask(array([[ 0., ...,  0.],
           ..., 
           [ 0., ...,  0.]]), <nibabel.nifti1.Nifti1Image object at 0x7fd40ee00ad0>)
    ___________________________________________________________unmask - 0.4s, 0.0min
    [Example] Learning maps using CanICA model
    [MultiNiftiMasker.fit] Loading data from [/home/varoquau/nilearn_data/adhd/data/0010042/0010042_rest_tshift_RPI_voreg_mni.nii.gz, /home/varoquau/nilearn_data/adhd/data/0010064/0010064_rest_tshift_RPI_voreg_mni.nii.gz, /home/varoquau/nilearn_
    [MultiNiftiMasker.fit] Computing mask
    [MultiNiftiMasker.transform] Resampling mask
    ________________________________________________________________________________
    [Memory] Calling sklearn.utils.extmath.randomized_svd...
    randomized_svd(array([[-0.002997, ..., -0.001381],
           ..., 
           [-0.002863, ...,  0.007679]]), n_iter=3, random_state=None, transpose=True, n_components=40)
    ___________________________________________________randomized_svd - 8.9s, 0.1min
    ________________________________________________________________________________
    [Memory] Calling sklearn.decomposition.fastica_.fastica...
    fastica(array([[ 0.002917, ...,  0.001367],
           ..., 
           [ 0.003475, ..., -0.002105]]), fun='cube', random_state=654217267, whiten=True)
    _________________________________________________________fastica - 16.5s, 0.3min
    [Example] Saving results
    ________________________________________________________________________________
    [Memory] Calling nilearn.masking.unmask...
    unmask(array([[ 0., ...,  0.],
           ..., 
           [ 0., ...,  0.]]), <nibabel.nifti1.Nifti1Image object at 0x7fd40ee9aa90>)
    ___________________________________________________________unmask - 0.2s, 0.0min


Visualize the results


.. code-block:: python

    from nilearn.plotting import (plot_prob_atlas, find_xyz_cut_coords, show,
                                  plot_stat_map)
    from nilearn.image import index_img

    # Selecting specific maps to display: maps were manually chosen to be similar
    indices = {dict_learning: 1, canica: 31}
    # We select relevant cut coordinates for displaying
    cut_component = index_img(components_imgs[0], indices[dict_learning])
    cut_coords = find_xyz_cut_coords(cut_component)
    for estimator, components in zip(estimators, components_imgs):
        # 4D plotting
        plot_prob_atlas(components, view_type="filled_contours",
                        title="%s" % names[estimator],
                        cut_coords=cut_coords, colorbar=False)
        # 3D plotting
        plot_stat_map(index_img(components, indices[estimator]),
                      title="%s" % names[estimator],
                      cut_coords=cut_coords, colorbar=False)
    show()



.. rst-class:: sphx-glr-horizontal


    *

      .. image:: /auto_examples/connectivity/images/sphx_glr_plot_compare_resting_state_decomposition_001.png
            :scale: 47

    *

      .. image:: /auto_examples/connectivity/images/sphx_glr_plot_compare_resting_state_decomposition_002.png
            :scale: 47

    *

      .. image:: /auto_examples/connectivity/images/sphx_glr_plot_compare_resting_state_decomposition_003.png
            :scale: 47

    *

      .. image:: /auto_examples/connectivity/images/sphx_glr_plot_compare_resting_state_decomposition_004.png
            :scale: 47




**Total running time of the script:**
(2 minutes 20.851 seconds)



.. container:: sphx-glr-download

    **Download Python source code:** :download:`plot_compare_resting_state_decomposition.py <plot_compare_resting_state_decomposition.py>`
