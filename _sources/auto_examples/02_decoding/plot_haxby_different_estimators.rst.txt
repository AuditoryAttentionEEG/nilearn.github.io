

.. _sphx_glr_auto_examples_02_decoding_plot_haxby_different_estimators.py:


Different classifiers in decoding the Haxby dataset
=====================================================

Here we compare different classifiers on a visual object recognition
decoding task.


We start by loading the data and applying simple transformations to it
-----------------------------------------------------------------------



.. code-block:: python


    # Fetch data using nilearn dataset fetcher
    from nilearn import datasets
    # by default 2nd subject data will be fetched
    haxby_dataset = datasets.fetch_haxby()

    # print basic information on the dataset
    print('First subject anatomical nifti image (3D) located is at: %s' %
          haxby_dataset.anat[0])
    print('First subject functional nifti image (4D) is located at: %s' %
          haxby_dataset.func[0])

    # load labels
    import numpy as np
    import pandas as pd
    labels = pd.read_csv(haxby_dataset.session_target[0], sep=" ")
    stimuli = labels['labels']
    # identify resting state labels in order to be able to remove them
    task_mask = (stimuli != 'rest')

    # find names of remaining active labels
    categories = stimuli[task_mask].unique()

    # extract tags indicating to which acquisition run a tag belongs
    session_labels = labels['chunks'][task_mask]

    # Load the fMRI data
    from nilearn.input_data import NiftiMasker

    # For decoding, standardizing is often very important
    mask_filename = haxby_dataset.mask_vt[0]
    masker = NiftiMasker(mask_img=mask_filename, standardize=True)
    func_filename = haxby_dataset.func[0]
    masked_timecourses = masker.fit_transform(
        func_filename)[task_mask]






.. rst-class:: sphx-glr-script-out

 Out::

    First subject anatomical nifti image (3D) located is at: /home/varoquau/nilearn_data/haxby2001/subj2/anat.nii.gz
    First subject functional nifti image (4D) is located at: /home/varoquau/nilearn_data/haxby2001/subj2/bold.nii.gz


Then we define the various classifiers that we use
---------------------------------------------------
A support vector classifier



.. code-block:: python

    from sklearn.svm import SVC
    svm = SVC(C=1., kernel="linear")

    # The logistic regression
    from sklearn.linear_model import (LogisticRegression,
                                      RidgeClassifier,
                                      RidgeClassifierCV,
                                      )
    logistic = LogisticRegression(C=1., penalty="l1")
    logistic_50 = LogisticRegression(C=50., penalty="l1")
    logistic_l2 = LogisticRegression(C=1., penalty="l2")

    # Cross-validated versions of these classifiers
    from sklearn.model_selection import GridSearchCV
    # GridSearchCV is slow, but note that it takes an 'n_jobs' parameter that
    # can significantly speed up the fitting process on computers with
    # multiple cores
    svm_cv = GridSearchCV(SVC(C=1., kernel="linear"),
                          param_grid={'C': [.1, .5, 1., 5., 10., 50., 100.]},
                          scoring='f1', n_jobs=1)

    logistic_cv = GridSearchCV(LogisticRegression(C=1., penalty="l1"),
                               param_grid={'C': [.1, .5, 1., 5., 10., 50., 100.]},
                               scoring='f1')
    logistic_l2_cv = GridSearchCV(LogisticRegression(C=1., penalty="l2"),
                                  param_grid={
                                      'C': [.1, .5, 1., 5., 10., 50., 100.]
                                  },
                                  scoring='f1')

    # The ridge classifier has a specific 'CV' object that can set it's
    # parameters faster than using a GridSearchCV
    ridge = RidgeClassifier()
    ridge_cv = RidgeClassifierCV()

    # A dictionary, to hold all our classifiers
    classifiers = {'SVC': svm,
                   'SVC cv': svm_cv,
                   'log l1': logistic,
                   'log l1 50': logistic_50,
                   'log l1 cv': logistic_cv,
                   'log l2': logistic_l2,
                   'log l2 cv': logistic_l2_cv,
                   'ridge': ridge,
                   'ridge cv': ridge_cv
                   }







Here we compute prediction scores
----------------------------------
Run time for all these classifiers



.. code-block:: python


    # Make a data splitting object for cross validation
    from sklearn.model_selection import LeaveOneGroupOut, cross_val_score
    cv = LeaveOneGroupOut()

    import time

    classifiers_scores = {}

    for classifier_name, classifier in sorted(classifiers.items()):
        classifiers_scores[classifier_name] = {}
        print(70 * '_')

        for category in categories:
            classification_target = stimuli[task_mask].isin([category])
            t0 = time.time()
            classifiers_scores[classifier_name][category] = cross_val_score(
                classifier,
                masked_timecourses,
                classification_target,
                cv=cv,
                groups=session_labels,
                scoring="f1",
            )

            print(
                "%10s: %14s -- scores: %1.2f +- %1.2f, time %.2fs" %
                (
                    classifier_name,
                    category,
                    classifiers_scores[classifier_name][category].mean(),
                    classifiers_scores[classifier_name][category].std(),
                    time.time() - t0,
                ),
            )





.. rst-class:: sphx-glr-script-out

 Out::

    ______________________________________________________________________
           SVC:       scissors -- scores: 0.41 +- 0.31, time 1.41s
           SVC:           face -- scores: 0.58 +- 0.24, time 1.05s
           SVC:            cat -- scores: 0.60 +- 0.25, time 1.43s
           SVC:           shoe -- scores: 0.56 +- 0.23, time 1.44s
           SVC:          house -- scores: 0.81 +- 0.28, time 0.83s
           SVC:   scrambledpix -- scores: 0.79 +- 0.17, time 1.13s
           SVC:         bottle -- scores: 0.53 +- 0.21, time 1.54s
           SVC:          chair -- scores: 0.42 +- 0.25, time 1.40s
    ______________________________________________________________________
        SVC cv:       scissors -- scores: 0.41 +- 0.31, time 32.32s
        SVC cv:           face -- scores: 0.58 +- 0.24, time 28.31s
        SVC cv:            cat -- scores: 0.60 +- 0.25, time 30.25s
        SVC cv:           shoe -- scores: 0.56 +- 0.23, time 30.62s
        SVC cv:          house -- scores: 0.81 +- 0.28, time 21.55s
        SVC cv:   scrambledpix -- scores: 0.79 +- 0.17, time 24.38s
        SVC cv:         bottle -- scores: 0.53 +- 0.21, time 33.24s
        SVC cv:          chair -- scores: 0.42 +- 0.25, time 31.46s
    ______________________________________________________________________
        log l1:       scissors -- scores: 0.43 +- 0.28, time 1.19s
        log l1:           face -- scores: 0.74 +- 0.13, time 0.68s
        log l1:            cat -- scores: 0.63 +- 0.23, time 1.05s
        log l1:           shoe -- scores: 0.49 +- 0.19, time 1.17s
        log l1:          house -- scores: 0.89 +- 0.13, time 0.53s
        log l1:   scrambledpix -- scores: 0.70 +- 0.18, time 0.61s
        log l1:         bottle -- scores: 0.47 +- 0.15, time 1.32s
        log l1:          chair -- scores: 0.44 +- 0.14, time 1.20s
    ______________________________________________________________________
     log l1 50:       scissors -- scores: 0.44 +- 0.24, time 1.70s
     log l1 50:           face -- scores: 0.67 +- 0.13, time 0.93s
     log l1 50:            cat -- scores: 0.66 +- 0.19, time 1.44s
     log l1 50:           shoe -- scores: 0.50 +- 0.19, time 1.61s
     log l1 50:          house -- scores: 0.86 +- 0.11, time 0.68s
     log l1 50:   scrambledpix -- scores: 0.74 +- 0.21, time 0.65s
     log l1 50:         bottle -- scores: 0.48 +- 0.18, time 1.90s
     log l1 50:          chair -- scores: 0.43 +- 0.11, time 1.86s
    ______________________________________________________________________
     log l1 cv:       scissors -- scores: 0.39 +- 0.27, time 15.48s
     log l1 cv:           face -- scores: 0.69 +- 0.19, time 10.71s
     log l1 cv:            cat -- scores: 0.53 +- 0.30, time 15.17s
     log l1 cv:           shoe -- scores: 0.50 +- 0.19, time 15.34s
     log l1 cv:          house -- scores: 0.85 +- 0.19, time 9.19s
     log l1 cv:   scrambledpix -- scores: 0.67 +- 0.17, time 8.85s
     log l1 cv:         bottle -- scores: 0.38 +- 0.18, time 16.90s
     log l1 cv:          chair -- scores: 0.42 +- 0.13, time 16.55s
    ______________________________________________________________________
        log l2:       scissors -- scores: 0.51 +- 0.15, time 1.66s
        log l2:           face -- scores: 0.55 +- 0.19, time 1.52s
        log l2:            cat -- scores: 0.54 +- 0.20, time 1.61s
        log l2:           shoe -- scores: 0.51 +- 0.17, time 1.57s
        log l2:          house -- scores: 0.63 +- 0.22, time 1.42s
        log l2:   scrambledpix -- scores: 0.78 +- 0.18, time 1.57s
        log l2:         bottle -- scores: 0.43 +- 0.20, time 1.61s
        log l2:          chair -- scores: 0.54 +- 0.17, time 1.84s
    ______________________________________________________________________
     log l2 cv:       scissors -- scores: 0.49 +- 0.15, time 26.17s
     log l2 cv:           face -- scores: 0.56 +- 0.20, time 20.50s
     log l2 cv:            cat -- scores: 0.55 +- 0.20, time 21.07s
     log l2 cv:           shoe -- scores: 0.51 +- 0.17, time 21.04s
     log l2 cv:          house -- scores: 0.64 +- 0.22, time 19.30s
     log l2 cv:   scrambledpix -- scores: 0.77 +- 0.18, time 19.34s
     log l2 cv:         bottle -- scores: 0.44 +- 0.21, time 21.87s
     log l2 cv:          chair -- scores: 0.53 +- 0.17, time 21.79s
    ______________________________________________________________________
         ridge:       scissors -- scores: 0.52 +- 0.22, time 0.41s
         ridge:           face -- scores: 0.62 +- 0.18, time 0.40s
         ridge:            cat -- scores: 0.43 +- 0.18, time 0.42s
         ridge:           shoe -- scores: 0.48 +- 0.21, time 0.41s
         ridge:          house -- scores: 0.90 +- 0.09, time 0.42s
         ridge:   scrambledpix -- scores: 0.79 +- 0.17, time 0.53s
         ridge:         bottle -- scores: 0.41 +- 0.19, time 0.41s
         ridge:          chair -- scores: 0.50 +- 0.21, time 0.47s
    ______________________________________________________________________
      ridge cv:       scissors -- scores: 0.56 +- 0.26, time 8.19s
      ridge cv:           face -- scores: 0.70 +- 0.13, time 7.25s
      ridge cv:            cat -- scores: 0.54 +- 0.22, time 7.71s
      ridge cv:           shoe -- scores: 0.49 +- 0.18, time 10.06s
      ridge cv:          house -- scores: 0.90 +- 0.13, time 11.83s
      ridge cv:   scrambledpix -- scores: 0.85 +- 0.11, time 9.12s
      ridge cv:         bottle -- scores: 0.46 +- 0.24, time 7.29s
      ridge cv:          chair -- scores: 0.51 +- 0.21, time 7.23s


Then we make a rudimentary diagram



.. code-block:: python

    import matplotlib.pyplot as plt
    plt.figure()

    tick_position = np.arange(len(categories))
    plt.xticks(tick_position, categories, rotation=45)

    for color, classifier_name in zip(
            ['b', 'c', 'm', 'g', 'y', 'k', '.5', 'r', '#ffaaaa'],
            sorted(classifiers)):
        score_means = [classifiers_scores[classifier_name][category].mean()
                       for category in categories]
        plt.bar(tick_position, score_means, label=classifier_name,
                width=.11, color=color)
        tick_position = tick_position + .09

    plt.ylabel('Classification accurancy (f1 score)')
    plt.xlabel('Visual stimuli category')
    plt.ylim(ymin=0)
    plt.legend(loc='lower center', ncol=3)
    plt.title(
        'Category-specific classification accuracy for different classifiers')
    plt.tight_layout()




.. image:: /auto_examples/02_decoding/images/sphx_glr_plot_haxby_different_estimators_001.png
    :align: center




Finally, w plot the face vs house map for the different classifiers



.. code-block:: python


    # Use the average EPI as a background
    from nilearn import image
    mean_epi_img = image.mean_img(func_filename)

    # Restrict the decoding to face vs house
    condition_mask = stimuli.isin(['face', 'house'])
    masked_timecourses = masked_timecourses[
        condition_mask[task_mask]]
    stimuli = (stimuli[condition_mask] == 'face')
    # Transform the stimuli to binary values
    stimuli.astype(np.int)

    from nilearn.plotting import plot_stat_map, show

    for classifier_name, classifier in sorted(classifiers.items()):
        classifier.fit(masked_timecourses, stimuli)

        if hasattr(classifier, 'coef_'):
            weights = classifier.coef_[0]
        elif hasattr(classifier, 'best_estimator_'):
            weights = classifier.best_estimator_.coef_[0]
        else:
            continue
        weight_img = masker.inverse_transform(weights)
        weight_map = weight_img.get_data()
        threshold = np.max(np.abs(weight_map)) * 1e-3
        plot_stat_map(weight_img, bg_img=mean_epi_img,
                      display_mode='z', cut_coords=[-15],
                      threshold=threshold,
                      title='%s: face vs house' % classifier_name)

    show()



.. rst-class:: sphx-glr-horizontal


    *

      .. image:: /auto_examples/02_decoding/images/sphx_glr_plot_haxby_different_estimators_002.png
            :scale: 47

    *

      .. image:: /auto_examples/02_decoding/images/sphx_glr_plot_haxby_different_estimators_003.png
            :scale: 47

    *

      .. image:: /auto_examples/02_decoding/images/sphx_glr_plot_haxby_different_estimators_004.png
            :scale: 47

    *

      .. image:: /auto_examples/02_decoding/images/sphx_glr_plot_haxby_different_estimators_005.png
            :scale: 47

    *

      .. image:: /auto_examples/02_decoding/images/sphx_glr_plot_haxby_different_estimators_006.png
            :scale: 47

    *

      .. image:: /auto_examples/02_decoding/images/sphx_glr_plot_haxby_different_estimators_007.png
            :scale: 47

    *

      .. image:: /auto_examples/02_decoding/images/sphx_glr_plot_haxby_different_estimators_008.png
            :scale: 47

    *

      .. image:: /auto_examples/02_decoding/images/sphx_glr_plot_haxby_different_estimators_009.png
            :scale: 47

    *

      .. image:: /auto_examples/02_decoding/images/sphx_glr_plot_haxby_different_estimators_010.png
            :scale: 47




**Total running time of the script:** ( 10 minutes  47.360 seconds)



.. container:: sphx-glr-footer


  .. container:: sphx-glr-download

     :download:`Download Python source code: plot_haxby_different_estimators.py <plot_haxby_different_estimators.py>`



  .. container:: sphx-glr-download

     :download:`Download Jupyter notebook: plot_haxby_different_estimators.ipynb <plot_haxby_different_estimators.ipynb>`

.. rst-class:: sphx-glr-signature

    `Generated by Sphinx-Gallery <https://sphinx-gallery.readthedocs.io>`_
