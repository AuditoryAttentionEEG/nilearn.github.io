

<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>3.2. fMRI decoding: predicting which objects a subject is viewing &mdash; NeuroImaging with the scikit-learn</title>
    
    <link rel="stylesheet" href="_static/nature.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '',
        VERSION:     '2010',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="_static/sidebar.js"></script>
    <link rel="shortcut icon" href="_static/favicon.ico"/>
    <link rel="top" title="NeuroImaging with the scikit-learn" href="index.html" />
    <link rel="up" title="3. Supervised learning" href="supervised_learning.html" />
    <link rel="next" title="4. Unsupervised learning" href="unsupervised_learning.html" />
    <link rel="prev" title="3.1. Decoding on simulated data" href="simulations.html" />
<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-22606712-2']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>

  </head>
  <body>

    <div class="header-wrapper">
      <div class="header">
          <p class="logo"><a href="index.html">
            <img src="_static/scikit-learn-logo-small.png" alt="Logo"/>
          </a>
          </p><div class="navbar">
          <ul>
          <!--	  
	    <li><a href="install.html">Download</a></li>
            <li><a href="support.html">Support</a></li>
	  -->
            <li><a href="#">fMRI decoding</a></li>
            <li><a href="auto_examples/index.html">Examples</a></li>
          <!--	  
	    <li><a href="modules/classes.html">Reference</a></li>
	  -->
       </ul>

<div class="search_form">

<div id="cse" style="width: 100%;"></div>
<script src="http://www.google.com/jsapi" type="text/javascript"></script>
<script type="text/javascript">
  google.load('search', '1', {language : 'en'});
  google.setOnLoadCallback(function() {
    var customSearchControl = new google.search.CustomSearchControl('016639176250731907682:tjtqbvtvij0');
    customSearchControl.setResultSetSize(google.search.Search.FILTERED_CSE_RESULTSET);
    var options = new google.search.DrawOptions();
    options.setAutoComplete(true);
    customSearchControl.draw('cse', options);
  }, true);
</script>

</div>
          </div> <!-- end navbar --></div>
    </div>

    <div class="content-wrapper">

      <div class="sphinxsidebar">
	<div class="sphinxsidebarwrapper">
	  <div class="rel">
	   
	<!-- XXX: when we have a 'module index' that appears in the link
	     bar, we will need to use the following ugly hack to avoid it
	     rellinks[1:]|reverse
	    -->
	<div class="rellink">
	<a href="simulations.html" title="3.1. Decoding on simulated data"
	    accesskey="P">Previous
	    <br>
	    <span class="smallrellink">
	    3.1. Decoding on...
	    </span>
	    <span class="hiddenrellink">
	    3.1. Decoding on simulated data
	    </span>
	    
	    </a>
	</div>
	    <div class="spacer">
	    &nbsp;
	    </div>
	
	<div class="rellink">
	<a href="unsupervised_learning.html" title="4. Unsupervised learning"
	    accesskey="N">Next
	    <br>
	    <span class="smallrellink">
	    4. Unsupervised ...
	    </span>
	    <span class="hiddenrellink">
	    4. Unsupervised learning
	    </span>
	    
	    </a>
	</div>
	<!-- Ad a link to the 'up' page -->
	<div class="spacer">
	&nbsp;
	</div>
	<div class="rellink">
	<a href="supervised_learning.html" title="3. Supervised learning" >
	Up
	<br>
	<span class="smallrellink">
	3. Supervised le...
	</span>
	<span class="hiddenrellink">
	3. Supervised learning
	</span>
	
	</a>
	</div>
    </div>
    <h3>This page</h3>
	<ul>
<li><a class="reference internal" href="#">3.2. fMRI decoding: predicting which objects a subject is viewing</a><ul>
<li><a class="reference internal" href="#data-loading-and-preprocessing">3.2.1. Data loading and preprocessing</a></li>
<li><a class="reference internal" href="#down-to-business-decoding-analysis">3.2.2. Down to business: decoding analysis</a><ul>
<li><a class="reference internal" href="#prediction-function-the-estimator">3.2.2.1. Prediction function: the estimator</a></li>
<li><a class="reference internal" href="#dimension-reduction">3.2.2.2. Dimension reduction</a></li>
<li><a class="reference internal" href="#launching-it-on-real-data-fit-train-and-predict-test">3.2.2.3. Launching it on real data: fit (train) and predict (test)</a></li>
<li><a class="reference internal" href="#visualising-the-results">3.2.2.4. Visualising the results</a></li>
<li><a class="reference internal" href="#cross-validation-measuring-prediction-performance">3.2.2.5. Cross-validation: measuring prediction performance</a></li>
</ul>
</li>
<li><a class="reference internal" href="#going-further-with-scikit-learn">3.2.3. Going further with scikit-learn</a><ul>
<li><a class="reference internal" href="#changing-the-prediction-function">3.2.3.1. Changing the prediction function</a></li>
<li><a class="reference internal" href="#changing-the-feature-selection">3.2.3.2. Changing the feature selection</a></li>
</ul>
</li>
</ul>
</li>
</ul>

    
    </div>
	  </div>


      <div class="content">
            
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="fmri-decoding-predicting-which-objects-a-subject-is-viewing">
<h1>3.2. fMRI decoding: predicting which objects a subject is viewing<a class="headerlink" href="#fmri-decoding-predicting-which-objects-a-subject-is-viewing" title="Permalink to this headline">¶</a></h1>
<div class="topic">
<p class="topic-title first">Objectives</p>
<p>At the end of this tutorial you will be able to:</p>
<blockquote>
<div><ol class="arabic simple">
<li>Load fMRI volumes in Python.</li>
<li>Perform a state-of-the-art decoding analysis of fMRI data.</li>
<li>Perform even more sophisticated analyzes of fMRI data.</li>
</ol>
</div></blockquote>
</div>
<div class="section" id="data-loading-and-preprocessing">
<h2>3.2.1. Data loading and preprocessing<a class="headerlink" href="#data-loading-and-preprocessing" title="Permalink to this headline">¶</a></h2>
<p>We launch ipython:</p>
<div class="highlight-python"><pre>$ ipython -pylab</pre>
</div>
<p>First, we load the data using the tutorial&#8217;s data downloader,
<a class="reference internal" href="generated/nisl.datasets.fetch_haxby.html#nisl.datasets.fetch_haxby" title="nisl.datasets.fetch_haxby"><tt class="xref py py-func docutils literal"><span class="pre">nisl.datasets.fetch_haxby</span></tt></a>:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">nisl</span> <span class="kn">import</span> <span class="n">datasets</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">fetch_haxby</span><span class="p">()</span>
<span class="n">fmri_data</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">data</span>
<span class="n">mask</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">mask</span>
<span class="n">affine</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">affine</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">target</span>
<span class="n">conditions</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">target_strings</span>
<span class="n">session</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">session</span>

<span class="c"># fmri_data.shape is (40, 64, 64, 1452)</span>
<span class="c"># and mask.shape is (40, 64, 64)</span>
</pre></div>
</div>
<p>Then we preprocess the data to make:</p>
<ul class="simple">
<li>compute the mean of the image to replace anatomic data</li>
<li>mask the data X and transpose the matrix, so that its shape becomes
(n_samples, n_features) (see <a class="reference internal" href="visualization.html#mask-4d-2-3d"><em>From 4D to 2D arrays</em></a> for a discussion on using
masks)</li>
<li>finally detrend the data for each session</li>
</ul>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="c"># Build the mean image because we have no anatomic data</span>
<span class="n">mean_img</span> <span class="o">=</span> <span class="n">fmri_data</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

<span class="c"># Process the data in order to have a two-dimensional design matrix X of</span>
<span class="c"># shape (n_samples, n_features).</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">fmri_data</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span><span class="o">.</span><span class="n">T</span>

<span class="c"># X.shape is (n_samples, n_features): (1452, 39912)</span>

<span class="c"># Detrend data on each session independently</span>
<span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">signal</span>
<span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">session</span><span class="p">):</span>
    <span class="n">X</span><span class="p">[</span><span class="n">session</span> <span class="o">==</span> <span class="n">s</span><span class="p">]</span> <span class="o">=</span> <span class="n">signal</span><span class="o">.</span><span class="n">detrend</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">session</span> <span class="o">==</span> <span class="n">s</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
<div class="green topic">
<p class="topic-title first"><strong>Exercise</strong></p>
<ol class="arabic simple">
<li>Extract the period of activity from the data (i.e. remove the remainder).</li>
</ol>
</div>
<div class="topic">
<p class="topic-title first">Solution</p>
<p>As &#8216;y == 0&#8217; in rest, we want to keep only time points for which
<cite>y != 0</cite>:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">session</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">y</span><span class="o">!=</span><span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">y</span><span class="o">!=</span><span class="mi">0</span><span class="p">],</span> <span class="n">session</span><span class="p">[</span><span class="n">y</span><span class="o">!=</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
</div>
<p>Here, we limit our analysis to the <cite>face</cite> and <cite>house</cite> conditions:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="c"># Keep only data corresponding to face or houses</span>
<span class="n">condition_mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">item</span> <span class="ow">in</span> <span class="p">(</span><span class="s">&#39;face&#39;</span><span class="p">,</span> <span class="s">&#39;house&#39;</span><span class="p">)</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">conditions</span><span class="p">])</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">condition_mask</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">condition_mask</span><span class="p">]</span>
<span class="n">session</span> <span class="o">=</span> <span class="n">session</span><span class="p">[</span><span class="n">condition_mask</span><span class="p">]</span>
<span class="n">conditions</span> <span class="o">=</span> <span class="n">conditions</span><span class="p">[</span><span class="n">condition_mask</span><span class="p">]</span>

<span class="c"># We now have n_samples, n_features = X.shape = 864, 39912</span>
<span class="n">n_samples</span><span class="p">,</span> <span class="n">n_features</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>

<span class="c"># We have 2 conditions</span>
<span class="n">n_conditions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="section" id="down-to-business-decoding-analysis">
<h2>3.2.2. Down to business: decoding analysis<a class="headerlink" href="#down-to-business-decoding-analysis" title="Permalink to this headline">¶</a></h2>
<div class="section" id="prediction-function-the-estimator">
<h3>3.2.2.1. Prediction function: the estimator<a class="headerlink" href="#prediction-function-the-estimator" title="Permalink to this headline">¶</a></h3>
<p>To perform decoding we construct an estimtor, predicting a condition
label <strong>y</strong> given a set <strong>X</strong> of images.</p>
<p>We define here a simple <a class="reference external" href="http://scikit-learn.org/stable/modules/svm.html">Support Vector Classification</a> (or SVC) with C=1, and a
linear kernel. We first import the correct module from scikit-learn and we
define the classifier:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="c">### Define the prediction function to be used.</span>
<span class="c"># Here we use a Support Vector Classification, with a linear kernel and C=1</span>
<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s">&#39;linear&#39;</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
</pre></div>
</div>
<p>Need some doc ?</p>
<div class="highlight-python"><pre>&gt;&gt;&gt; clf ? 
Type:             SVC
Base Class:       &lt;class 'sklearn.svm.libsvm.SVC'&gt;
String Form:
SVC(kernel=linear, C=1.0, probability=False, degree=3, coef0=0.0, eps=0.001,
cache_size=100.0, shrinking=True, gamma=0.0)
Namespace:        Interactive
Docstring:
    C-Support Vector Classification.
    Parameters
    ----------
    C : float, optional (default=1.0)
        penalty parameter C of the error term.
...</pre>
</div>
<p>Or go to the <a class="reference external" href="http://scikit-learn.org/modules/svm.html">scikit-learn
documentation</a>
We use a SVC here, but we can use
<a class="reference external" href="http://scikit-learn.org/stable/supervised_learning.html">many other
classifiers</a></p>
</div>
<div class="section" id="dimension-reduction">
<h3>3.2.2.2. Dimension reduction<a class="headerlink" href="#dimension-reduction" title="Permalink to this headline">¶</a></h3>
<p>As there are a very large number of voxels and not all are useful for
face vs house prediction, we add a <a class="reference external" href="http://scikit-learn.org/stable/modules/feature_selection.html">feature selection</a>
procedure. The idea is to select the <cite>k</cite> voxels most correlated to the
task.</p>
<p>For this, we need to import the correct module and define a simple F-score
based feature selection (a.k.a.
<a class="reference external" href="http://en.wikipedia.org/wiki/Analysis_of_variance#The_F-test">Anova</a>):</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">SelectKBest</span><span class="p">,</span> <span class="n">f_classif</span>

<span class="c">### Define the dimension reduction to be used.</span>
<span class="c"># Here we use a classical univariate feature selection based on F-test,</span>
<span class="c"># namely Anova. We set the number of features to be selected to 1000</span>
<span class="n">feature_selection</span> <span class="o">=</span> <span class="n">SelectKBest</span><span class="p">(</span><span class="n">f_classif</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>

<span class="c"># We have our classifier (SVC), our feature selection (SelectKBest), and now,</span>
<span class="c"># we can plug them together in a *pipeline* that performs the two operations</span>
<span class="c"># successively:</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="n">anova_svc</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([(</span><span class="s">&#39;anova&#39;</span><span class="p">,</span> <span class="n">feature_selection</span><span class="p">),</span> <span class="p">(</span><span class="s">&#39;svc&#39;</span><span class="p">,</span> <span class="n">clf</span><span class="p">)])</span>
</pre></div>
</div>
</div>
<div class="section" id="launching-it-on-real-data-fit-train-and-predict-test">
<h3>3.2.2.3. Launching it on real data: fit (train) and predict (test)<a class="headerlink" href="#launching-it-on-real-data-fit-train-and-predict-test" title="Permalink to this headline">¶</a></h3>
<p>In scikit-learn, the prediction function has a very simple API:</p>
<ul class="simple">
<li>a <em>fit</em> function that &#8220;learns&#8221; the parameters of the model from the data.
Thus, we need to give some training data to <em>fit</em>.</li>
<li>a <em>predict</em> function that &#8220;predicts&#8221; a target from new data.
Here, we just have to give the new set of images (as the target should be
unknown):</li>
</ul>
<div class="highlight-python"><div class="highlight"><pre><span class="n">anova_svc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">anova_svc</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Warning ! Do not do this at home:</strong> the prediction that we obtain here
is to good to be true (see next paragraph). Here we are just doing a
sanity check.</p>
</div>
<div class="section" id="visualising-the-results">
<h3>3.2.2.4. Visualising the results<a class="headerlink" href="#visualising-the-results" title="Permalink to this headline">¶</a></h3>
<p>We can visualize the result of our algorithm:</p>
<ul class="simple">
<li>we first get the support vectors of the SVC and revert the feature
selection mechanism</li>
<li>we remove the mask</li>
<li>then we overlay our previousely-computed, mean image with our support vectors</li>
</ul>
<div class="figure align-center">
<a class="reference external image-reference" href="auto_examples/plot_haxby_decoding.html"><img alt="_images/plot_haxby_decoding_1.png" src="_images/plot_haxby_decoding_1.png" style="width: 480.0px; height: 360.0px;" /></a>
</div>
<div class="highlight-python"><div class="highlight"><pre><span class="c">### Look at the discriminating weights</span>
<span class="n">svc</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">support_vectors_</span>
<span class="c"># reverse feature selection</span>
<span class="n">svc</span> <span class="o">=</span> <span class="n">feature_selection</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">svc</span><span class="p">)</span>
<span class="c"># reverse masking</span>
<span class="n">act</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">mean_img</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">act</span><span class="p">[</span><span class="n">mask</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">svc</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="c"># We use a masked array so that the voxels at &#39;0&#39; are displayed</span>
<span class="c"># transparently</span>
<span class="n">act</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ma</span><span class="o">.</span><span class="n">masked_array</span><span class="p">(</span><span class="n">act</span><span class="p">,</span> <span class="n">act</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span>

<span class="c">### Create the figure on z=23</span>
<span class="kn">import</span> <span class="nn">pylab</span> <span class="kn">as</span> <span class="nn">pl</span>
<span class="n">pl</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s">&#39;off&#39;</span><span class="p">)</span>
<span class="n">pl</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s">&#39;SVM vectors&#39;</span><span class="p">)</span>
<span class="n">pl</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">rot90</span><span class="p">(</span><span class="n">mean_img</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">16</span><span class="p">]),</span> <span class="n">cmap</span><span class="o">=</span><span class="n">pl</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">gray</span><span class="p">,</span>
          <span class="n">interpolation</span><span class="o">=</span><span class="s">&#39;nearest&#39;</span><span class="p">)</span>
<span class="n">pl</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">rot90</span><span class="p">(</span><span class="n">act</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">16</span><span class="p">]),</span> <span class="n">cmap</span><span class="o">=</span><span class="n">pl</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">hot</span><span class="p">,</span>
          <span class="n">interpolation</span><span class="o">=</span><span class="s">&#39;nearest&#39;</span><span class="p">)</span>
<span class="n">pl</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c"># Saving the results as a Nifti file may also be important</span>
<span class="kn">import</span> <span class="nn">nibabel</span>
<span class="n">img</span> <span class="o">=</span> <span class="n">nibabel</span><span class="o">.</span><span class="n">Nifti1Image</span><span class="p">(</span><span class="n">act</span><span class="p">,</span> <span class="n">affine</span><span class="p">)</span>
<span class="n">nibabel</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="s">&#39;haxby_face_vs_house.nii&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="cross-validation-measuring-prediction-performance">
<h3>3.2.2.5. Cross-validation: measuring prediction performance<a class="headerlink" href="#cross-validation-measuring-prediction-performance" title="Permalink to this headline">¶</a></h3>
<p>However, the last analysis is <em>wrong</em>, as we have learned and tested on
the same set of data. We need to use a cross-validation to split the data
into different sets.</p>
<p>In scikit-learn, a cross-validation is simply a function that generates
the index of the folds within a loop.
So, now, we can apply the previously defined <em>pipeline</em> with the
cross-validation:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">sklearn.cross_validation</span> <span class="kn">import</span> <span class="n">LeaveOneLabelOut</span>

<span class="c">### Define the cross-validation scheme used for validation.</span>
<span class="c"># Here we use a LeaveOneLabelOut cross-validation on the session, which</span>
<span class="c"># corresponds to a leave-one-session-out</span>
<span class="n">cv</span> <span class="o">=</span> <span class="n">LeaveOneLabelOut</span><span class="p">(</span><span class="n">session</span><span class="p">)</span>

<span class="c">### Compute the prediction accuracy for the different folds (i.e. session)</span>
<span class="n">cv_scores</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="ow">in</span> <span class="n">cv</span><span class="p">:</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">anova_svc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">train</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">train</span><span class="p">])</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">test</span><span class="p">])</span>
    <span class="n">cv_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">y_pred</span> <span class="o">==</span> <span class="n">y</span><span class="p">[</span><span class="n">test</span><span class="p">])</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="n">y</span><span class="p">[</span><span class="n">test</span><span class="p">])))</span>
</pre></div>
</div>
<p>But we are lazy people, so there is a specific
function, <em>cross_val_score</em> that computes for you the results for the
different folds of cross-validation:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.cross_validation</span> <span class="kn">import</span> <span class="n">cross_val_score</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cv_scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">anova_svc</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">cv</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
<p>If you are the happy owner of a multiple processors computer you can
speed up the computation by using n_jobs=-1, which will spread the
computation equally across all processors (this will probably not work
under Windows):</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">cv_scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">anova_svc</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">cv</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span> 
</pre></div>
</div>
<p><strong>Prediction accuracy</strong> We can take a look to the results of the
<em>cross_val_score</em> function:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">cv_scores</span> 
<span class="go">array([ 1.        ,  1.        ,  1.        ,  1.        ,  1.        ,</span>
<span class="go">        1.        ,  1.        ,  0.83333333,  1.        ,  1.        ,</span>
<span class="go">        1.        ,  1.        ])</span>
</pre></div>
</div>
<p>This is simply the prediction score for each fold, i.e. the fraction of
correct predictions on the left-out data.</p>
<div class="green topic">
<p class="topic-title first"><strong>Exercise</strong></p>
<ol class="arabic simple">
<li>Compute the mean prediction accuracy using <em>cv_scores</em></li>
</ol>
</div>
<div class="topic">
<p class="topic-title first">Solution</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">classification_accuracy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">cv_scores</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">classification_accuracy</span> 
<span class="go">0.74421296296296291</span>
</pre></div>
</div>
</div>
<p>We have a total prediction accuracy of 74% across the different folds.</p>
<p>We can add a line to print the results:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="c">### Return the corresponding mean prediction accuracy</span>
<span class="n">classification_accuracy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">cv_scores</span><span class="p">)</span>

<span class="c">### Printing the results</span>
<span class="k">print</span> <span class="s">&quot;=== ANOVA ===&quot;</span>
<span class="k">print</span> <span class="s">&quot;Classification accuracy: </span><span class="si">%f</span><span class="s">&quot;</span> <span class="o">%</span> <span class="n">classification_accuracy</span><span class="p">,</span> \
    <span class="s">&quot; / Chance level: </span><span class="si">%f</span><span class="s">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">/</span> <span class="n">n_conditions</span><span class="p">)</span>
<span class="c"># Classification accuracy: 0.986111  / Chance level: 0.500000</span>
</pre></div>
</div>
<div class="topic">
<p class="topic-title first">Final script</p>
<p>The complete script can be found as
<a class="reference internal" href="auto_examples/plot_haxby_decoding.html#example-tutorial-plot-haxby-decoding-py"><em>an example</em></a>.
Now, all you have to do is to publish the results :)</p>
</div>
</div>
</div>
<div class="section" id="going-further-with-scikit-learn">
<h2>3.2.3. Going further with scikit-learn<a class="headerlink" href="#going-further-with-scikit-learn" title="Permalink to this headline">¶</a></h2>
<p>We have seen a very simple analysis with scikit-learn, but it may be
interesting to explore the <a class="reference external" href="http://scikit-learn.org/stable/supervised_learning.html">wide variety of supervised learning
algorithms in the scikit-learn</a>.</p>
<div class="section" id="changing-the-prediction-function">
<h3>3.2.3.1. Changing the prediction function<a class="headerlink" href="#changing-the-prediction-function" title="Permalink to this headline">¶</a></h3>
<p>We now see how one can easily change the prediction function, if needed.
We can try the <a class="reference external" href="http://scikit-learn.org/auto_examples/plot_lda_qda.html">Linear Discriminant Analysis (LDA)</a></p>
<p>Import the module:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.lda</span> <span class="kn">import</span> <span class="n">LDA</span>
</pre></div>
</div>
<p>Construct the new prediction function and use it in a pipeline:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lda</span> <span class="o">=</span> <span class="n">LDA</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">anova_lda</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([(</span><span class="s">&#39;anova&#39;</span><span class="p">,</span> <span class="n">feature_selection</span><span class="p">),</span> <span class="p">(</span><span class="s">&#39;LDA&#39;</span><span class="p">,</span> <span class="n">lda</span><span class="p">)])</span>
</pre></div>
</div>
<p>and recompute the cross-validation score:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">cv_scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">anova_lda</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">cv</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">classification_accuracy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">cv_scores</span><span class="p">)</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="s">&quot;Classification accuracy: </span><span class="si">%f</span><span class="s">&quot;</span> <span class="o">%</span> <span class="n">classification_accuracy</span><span class="p">,</span> \
<span class="gp">... </span>    <span class="s">&quot; / Chance level: </span><span class="si">%f</span><span class="s">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">/</span> <span class="n">n_conditions</span><span class="p">)</span> 
<span class="go">Classification accuracy: 0.728009   / Chance level: 0.125000</span>
</pre></div>
</div>
</div>
<div class="section" id="changing-the-feature-selection">
<h3>3.2.3.2. Changing the feature selection<a class="headerlink" href="#changing-the-feature-selection" title="Permalink to this headline">¶</a></h3>
<p>Let&#8217;s say that you want a more sophisticated feature selection, for example a
<a class="reference external" href="http://scikit-learn.org/stable/modules/feature_selection.html#recursive-feature-elimination">Recursive Feature Elimination (RFE)</a></p>
<p>Import the module:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">RFE</span>
</pre></div>
</div>
<p>Construct your new fancy selection:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">rfe</span> <span class="o">=</span> <span class="n">RFE</span><span class="p">(</span><span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s">&#39;linear&#39;</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="mf">1.</span><span class="p">),</span> <span class="mi">50</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mf">0.25</span><span class="p">)</span>
</pre></div>
</div>
<p>and create a new pipeline:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">rfe_svc</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([(</span><span class="s">&#39;rfe&#39;</span><span class="p">,</span> <span class="n">rfe</span><span class="p">),</span> <span class="p">(</span><span class="s">&#39;svc&#39;</span><span class="p">,</span> <span class="n">clf</span><span class="p">)])</span>
</pre></div>
</div>
<p>and recompute the cross-validation score:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">cv_scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">rfe_svc</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">cv</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">verbose</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span> 
</pre></div>
</div>
<p>But, be aware that this can take A WHILE...</p>
</div>
</div>
</div>


          </div>
        </div>
      </div>
        <div class="clearer"></div>
      </div>
    </div>
  

    <div class="footer">
        &copy; INRIA Parietal 2010.
      Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 1.1.3. Design by <a href="http://webylimonada.com">Web y Limonada</a>.
    <span style="padding-left: 5ex;">
    <a href="_sources/haxby_decoding.txt"
	    rel="nofollow">Show this page source</a>
    </span>
    </div>
     <div class="rel">
    
	<!-- XXX: when we have a 'module index' that appears in the link
	     bar, we will need to use the following ugly hack to avoid it
	rellinks[1:]|reverse
	-->
    <div class="buttonPrevious">
      <a href="simulations.html">
        Previous
      </a>  
    </div>
    <div class="buttonNext">
      <a href="unsupervised_learning.html">
        Next
      </a>  
    </div>
    
     </div>
     <script type="text/javascript">
       $("div.buttonNext, div.buttonPrevious").hover(
           function () {
               $(this).css('background-color', '#FF9C34');
           },
           function () {
               $(this).css('background-color', '#A7D6E2');
           }
       );
     </script>
  </body>
</html>