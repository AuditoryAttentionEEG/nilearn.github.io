
<!DOCTYPE html>


<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Nilearn: Machine learning for NeuroImaging in Python &#8212; Machine learning for NeuroImaging</title>
    
    <link rel="stylesheet" href="../../_static/nature.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/gallery.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../../',
        VERSION:     '0.4.0',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true,
        SOURCELINK_SUFFIX: '.txt'
      };
    </script>
    <script type="text/javascript" src="../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../_static/doctools.js"></script>
    <script type="text/javascript" src="../../_static/copybutton.js"></script>
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="7.10.9. nilearn.plotting.plot_glass_brain" href="nilearn.plotting.plot_glass_brain.html" />
    <link rel="prev" title="7.10.7. nilearn.plotting.plot_roi" href="nilearn.plotting.plot_roi.html" />
<meta content="True" name="HandheldFriendly">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0">
<meta name="keywords" content="nilearn, neuroimaging, python, neuroscience, machinelearning">
<script type="text/javascript">
$(function () {
    // Lock the table of content to a fixed position once we scroll enough
    var top = 105 + $('.sphinxsidebarwrapper').offset().top - parseFloat($('.sphinxsidebarwrapper').css('margin-top').replace(/auto/, 0)),
        sections = {},
        i        = 0,
	url	 = document.URL.replace(/#.*$/, ""),
	current_section = 0;

    // Grab positions of our sections
    $('.headerlink').each(function(){
        sections[this.href.replace(url, '')] = $(this).offset().top - 50;
    });

    $(window).scroll(function(event) {
	var pos   = $(window).scrollTop();
	// Lock the table of content to a fixed position once we scroll enough
	if(pos > top){
	    //begin to scroll
	    $('.sphinxsidebarwrapper').css("position", "fixed");
	    $('.sphinxsidebarwrapper').css("top", -105);
	}
	else{
	    //lock it back into place
	    $('.sphinxsidebarwrapper').css("position", "relative");
	    $('.sphinxsidebarwrapper').css("top",0);
	}

	// Highlight the current section
	$('a.internal').removeClass('active');
        for(i in sections){
            if(sections[i] > pos){
		break;
            };
	    if($('a.internal[href$="' + i + '"]').is(':visible')){
		current_section = i;
	    };
        }
	$('a.internal[href$="' + current_section + '"]').addClass('active');
    });

});
</script>


<script type="text/javascript">

        var _gaq = _gaq || [];
        _gaq.push(['_setAccount', 'UA-41920728-1']);
        _gaq.push(['_trackPageview']);

        (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
        })();
    </script>

  </head>
  <body role="document">
<div id="logo-banner">
  <div class="logo">
    <a href="../../index.html">
      <img src="../../_static/nilearn-logo.png" alt="Nilearn logo"  border="0" />
    </a>
  </div>
  <!-- A tag cloud to make it easy for people to find what they are
                         looking for -->
 <div class="tags">
  <ul>
    <li>
      <big><a href="../../auto_examples/decoding/plot_haxby_anova_svm.html">SVM</a></big>
    </li>
    <li>
      <small><a href="../../connectivity/parcellating.html">Ward
          clustering</a></small>
    </li>
    <li>
      <a href="../../decoding/searchlight.html">Searchlight</a>
    </li>
    <li>
      <big><a href="../../connectivity/resting_state_networks.html">ICA</a></big>
    </li>
    <li>
      <a href="../../manipulating_images/data_preparation.html">Nifti IO</a>
    </li>
    <li>
      <a href="../reference.html#module-nilearn.datasets">Datasets</a>
    </li>
  </ul>
 </div>

  <div class="banner">
    <h1>Nilearn:</h1>
    <h2>Machine learning for Neuro-Imaging in Python</h2>
  </div>
  <div class="search_form">
    <div id="cse" style="width: 100%;"></div>
    <script src="http://www.google.com/jsapi" type="text/javascript"></script>
    <script type="text/javascript">
      google.load('search', '1', {language : 'en'});
      google.setOnLoadCallback(function() {
      var customSearchControl = new google.search.CustomSearchControl('014136483057745874622:r-npolb1uki');
      customSearchControl.setResultSetSize(google.search.Search.FILTERED_CSE_RESULTSET);
      var options = new google.search.DrawOptions();
      options.setAutoComplete(true);
      customSearchControl.draw('cse', options);
      }, true);
    </script>
  </div>
</div>



    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="nilearn.plotting.plot_glass_brain.html" title="7.10.9. nilearn.plotting.plot_glass_brain"
             accesskey="N">next</a></li>
        <li class="right" >
          <a href="nilearn.plotting.plot_roi.html" title="7.10.7. nilearn.plotting.plot_roi"
             accesskey="P">previous</a> |</li>
<li><a href="../../index.html">Nilearn Home</a> |&nbsp;</li>
<li><a href="../../user_guide.html">User Guide</a> |&nbsp;</li>
<li><a href="../../auto_examples/index.html">Examples</a> |&nbsp;</li>
<li><a href="../reference.html">Reference</a> |&nbsp;</li>
<li id="navbar-about"><a href="../../authors.html">About</a>|&nbsp;</li>
<li id="navbar-ecosystem"><a href="http://www.nipy.org/">Nipy ecosystem</a></li>

          <li class="nav-item nav-item-1"><a href="../../user_guide.html" >User guide: table of contents</a> &#187;</li>
          <li class="nav-item nav-item-2"><a href="../reference.html" accesskey="U">7. Reference documentation: all nilearn functions</a> &#187;</li> 
      </ul>
    </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">


<h4> Giving credit </h4>
  <ul class="simple">
    <li><p>Please consider <a href="../../authors.html#citing">citing the
                    papers</a>.</p></li>
  </ul>

  <h3><a href="../../index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">7.10.8. nilearn.plotting.plot_stat_map</a><ul>
<li><a class="reference internal" href="#examples-using-nilearn-plotting-plot-stat-map">7.10.8.1. Examples using <code class="docutils literal"><span class="pre">nilearn.plotting.plot_stat_map</span></code></a></li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="nilearn.plotting.plot_roi.html"
                        title="previous chapter">7.10.7. nilearn.plotting.plot_roi</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="nilearn.plotting.plot_glass_brain.html"
                        title="next chapter">7.10.9. nilearn.plotting.plot_glass_brain</a></p>

<div class="navbar">
</div> <!-- end navbar -->

<script type="text/javascript">$('#searchbox-ml').show(0);</script>
<script type="text/javascript">$('#searchbox-site').show(0);</script>


        </div>
      </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">This page is a reference documentation. It only explains the
function signature, and not how to use it. Please refer to the
<a class="reference internal" href="../../user_guide.html#user-guide"><span class="std std-ref">user guide</span></a> for the big picture.</p>
</div>
<div class="section" id="nilearn-plotting-plot-stat-map">
<h1>7.10.8. nilearn.plotting.plot_stat_map<a class="headerlink" href="#nilearn-plotting-plot-stat-map" title="Permalink to this headline">¶</a></h1>
<dl class="function">
<dt id="nilearn.plotting.plot_stat_map">
<code class="descclassname">nilearn.plotting.</code><code class="descname">plot_stat_map</code><span class="sig-paren">(</span><em>stat_map_img</em>, <em>bg_img=&lt;MNI152Template&gt;</em>, <em>cut_coords=None</em>, <em>output_file=None</em>, <em>display_mode='ortho'</em>, <em>colorbar=True</em>, <em>figure=None</em>, <em>axes=None</em>, <em>title=None</em>, <em>threshold=1e-06</em>, <em>annotate=True</em>, <em>draw_cross=True</em>, <em>black_bg='auto'</em>, <em>cmap=&lt;matplotlib.colors.LinearSegmentedColormap object&gt;</em>, <em>symmetric_cbar='auto'</em>, <em>dim='auto'</em>, <em>vmax=None</em>, <em>resampling_interpolation='continuous'</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#nilearn.plotting.plot_stat_map" title="Permalink to this definition">¶</a></dt>
<dd><p>Plot cuts of an ROI/mask image (by default 3 cuts: Frontal, Axial, and
Lateral)</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>stat_map_img</strong> : Niimg-like object</p>
<blockquote>
<div><p>See <a class="reference external" href="http://nilearn.github.io/manipulating_images/input_output.html">http://nilearn.github.io/manipulating_images/input_output.html</a>
The statistical map image</p>
</div></blockquote>
<p><strong>bg_img</strong> : Niimg-like object</p>
<blockquote>
<div><p>See <a class="reference external" href="http://nilearn.github.io/manipulating_images/input_output.html">http://nilearn.github.io/manipulating_images/input_output.html</a>
The background image that the ROI/mask will be plotted on top of.
If nothing is specified, the MNI152 template will be used.
To turn off background image, just pass &#8220;bg_img=False&#8221;.</p>
</div></blockquote>
<p><strong>cut_coords</strong> : None, a tuple of floats, or an integer</p>
<blockquote>
<div><p>The MNI coordinates of the point where the cut is performed
If display_mode is &#8216;ortho&#8217;, this should be a 3-tuple: (x, y, z)
For display_mode == &#8216;x&#8217;, &#8216;y&#8217;, or &#8216;z&#8217;, then these are the
coordinates of each cut in the corresponding direction.
If None is given, the cuts is calculated automaticaly.
If display_mode is &#8216;x&#8217;, &#8216;y&#8217; or &#8216;z&#8217;, cut_coords can be an integer,
in which case it specifies the number of cuts to perform</p>
</div></blockquote>
<p><strong>output_file</strong> : string, or None, optional</p>
<blockquote>
<div><p>The name of an image file to export the plot to. Valid extensions
are .png, .pdf, .svg. If output_file is not None, the plot
is saved to a file, and the display is closed.</p>
</div></blockquote>
<p><strong>display_mode</strong> : {&#8216;ortho&#8217;, &#8216;x&#8217;, &#8216;y&#8217;, &#8216;z&#8217;, &#8216;yx&#8217;, &#8216;xz&#8217;, &#8216;yz&#8217;}</p>
<blockquote>
<div><p>Choose the direction of the cuts: &#8216;x&#8217; - sagittal, &#8216;y&#8217; - coronal,
&#8216;z&#8217; - axial, &#8216;ortho&#8217; - three cuts are performed in orthogonal
directions.</p>
</div></blockquote>
<p><strong>colorbar</strong> : boolean, optional</p>
<blockquote>
<div><p>If True, display a colorbar on the right of the plots.</p>
</div></blockquote>
<p><strong>figure</strong> : integer or matplotlib figure, optional</p>
<blockquote>
<div><p>Matplotlib figure used or its number. If None is given, a
new figure is created.</p>
</div></blockquote>
<p><strong>axes</strong> : matplotlib axes or 4 tuple of float: (xmin, ymin, width, height), optional</p>
<blockquote>
<div><p>The axes, or the coordinates, in matplotlib figure space,
of the axes used to display the plot. If None, the complete
figure is used.</p>
</div></blockquote>
<p><strong>title</strong> : string, optional</p>
<blockquote>
<div><p>The title displayed on the figure.</p>
</div></blockquote>
<p><strong>threshold</strong> : a number, None, or &#8216;auto&#8217;</p>
<blockquote>
<div><p>If None is given, the image is not thresholded.
If a number is given, it is used to threshold the image:
values below the threshold (in absolute value) are plotted
as transparent. If auto is given, the threshold is determined
magically by analysis of the image.</p>
</div></blockquote>
<p><strong>annotate</strong> : boolean, optional</p>
<blockquote>
<div><p>If annotate is True, positions and left/right annotation
are added to the plot.</p>
</div></blockquote>
<p><strong>draw_cross</strong> : boolean, optional</p>
<blockquote>
<div><p>If draw_cross is True, a cross is drawn on the plot to
indicate the cut plosition.</p>
</div></blockquote>
<p><strong>black_bg</strong> : boolean, optional</p>
<blockquote>
<div><p>If True, the background of the image is set to be black. If
you wish to save figures with a black background, you
will need to pass &#8220;facecolor=&#8217;k&#8217;, edgecolor=&#8217;k&#8217;&#8221;
to matplotlib.pyplot.savefig.</p>
</div></blockquote>
<p><strong>cmap</strong> : matplotlib colormap, optional</p>
<blockquote>
<div><p>The colormap for specified image. The ccolormap <em>must</em> be
symmetrical.</p>
</div></blockquote>
<p><strong>symmetric_cbar</strong> : boolean or &#8216;auto&#8217;, optional, default &#8216;auto&#8217;</p>
<blockquote>
<div><p>Specifies whether the colorbar should range from -vmax to vmax
or from vmin to vmax. Setting to &#8216;auto&#8217; will select the latter if
the range of the whole image is either positive or negative.
Note: The colormap will always be set to range from -vmax to vmax.</p>
</div></blockquote>
<p><strong>dim</strong> : float, &#8216;auto&#8217; (by default), optional</p>
<blockquote>
<div><p>Dimming factor applied to background image. By default, automatic
heuristics are applied based upon the background image intensity.
Accepted float values, where a typical scan is between -2 and 2
(-2 = increase constrast; 2 = decrease contrast), but larger values
can be used for a more pronounced effect. 0 means no dimming.</p>
</div></blockquote>
<p><strong>vmax</strong> : float</p>
<blockquote>
<div><p>Upper bound for plotting, passed to matplotlib.pyplot.imshow</p>
</div></blockquote>
<p><strong>resampling_interpolation</strong> : str</p>
<blockquote class="last">
<div><p>Interpolation to use when resampling the image to the destination
space. Can be &#8220;continuous&#8221; (default) to use 3rd-order spline
interpolation, or &#8220;nearest&#8221; to use nearest-neighbor mapping.
&#8220;nearest&#8221; is faster but can be noisier in some cases.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
<div class="admonition seealso">
<p class="first admonition-title">See also</p>
<dl class="last docutils">
<dt><a class="reference internal" href="nilearn.plotting.plot_anat.html#nilearn.plotting.plot_anat" title="nilearn.plotting.plot_anat"><code class="xref py py-obj docutils literal"><span class="pre">nilearn.plotting.plot_anat</span></code></a></dt>
<dd>To simply plot anatomical images</dd>
<dt><a class="reference internal" href="nilearn.plotting.plot_epi.html#nilearn.plotting.plot_epi" title="nilearn.plotting.plot_epi"><code class="xref py py-obj docutils literal"><span class="pre">nilearn.plotting.plot_epi</span></code></a></dt>
<dd>To simply plot raw EPI images</dd>
<dt><a class="reference internal" href="nilearn.plotting.plot_glass_brain.html#nilearn.plotting.plot_glass_brain" title="nilearn.plotting.plot_glass_brain"><code class="xref py py-obj docutils literal"><span class="pre">nilearn.plotting.plot_glass_brain</span></code></a></dt>
<dd>To plot maps in a glass brain</dd>
</dl>
</div>
<p class="rubric">Notes</p>
<p>Arrays should be passed in numpy convention: (x, y, z)
ordered.</p>
<p>For visualization, non-finite values found in passed &#8216;stat_map_img&#8217; or
&#8216;bg_img&#8217; are set to zero.</p>
</dd></dl>

<div class="section" id="examples-using-nilearn-plotting-plot-stat-map">
<h2>7.10.8.1. Examples using <code class="docutils literal"><span class="pre">nilearn.plotting.plot_stat_map</span></code><a class="headerlink" href="#examples-using-nilearn-plotting-plot-stat-map" title="Permalink to this headline">¶</a></h2>
<div class="sphx-glr-thumbcontainer" tooltip="Here we discover how to work with 3D and 4D niimgs. "><div class="figure" id="id1">
<img alt="../../_images/sphx_glr_plot_3d_and_4d_niimg_thumb.png" src="../../_images/sphx_glr_plot_3d_and_4d_niimg_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/plot_3d_and_4d_niimg.html#sphx-glr-auto-examples-plot-3d-and-4d-niimg-py"><span class="std std-ref">3D and 4D niimgs: handling and visualizing</span></a></span></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Here is a simple tutorial on decoding with nilearn. It reproduces the Haxby 2001 study on a fac..."><div class="figure" id="id2">
<img alt="../../_images/sphx_glr_plot_decoding_tutorial_thumb.png" src="../../_images/sphx_glr_plot_decoding_tutorial_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/plot_decoding_tutorial.html#sphx-glr-auto-examples-plot-decoding-tutorial-py"><span class="std std-ref">A introduction tutorial to fMRI decoding</span></a></span></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="project a 3D statistical map onto a cortical mesh using :func:`nilearn.surface.vol_to_surf`. Di..."><div class="figure" id="id3">
<img alt="../../_images/sphx_glr_plot_3d_map_to_surface_projection_thumb.png" src="../../_images/sphx_glr_plot_3d_map_to_surface_projection_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/01_plotting/plot_3d_map_to_surface_projection.html#sphx-glr-auto-examples-01-plotting-plot-3d-map-to-surface-projection-py"><span class="std std-ref">Making a surface plot of a 3D statistical map</span></a></span></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="In this example, we demonstrate how to use plotting options from nilearn essential in visualizi..."><div class="figure" id="id4">
<img alt="../../_images/sphx_glr_plot_demo_more_plotting_thumb.png" src="../../_images/sphx_glr_plot_demo_more_plotting_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/01_plotting/plot_demo_more_plotting.html#sphx-glr-auto-examples-01-plotting-plot-demo-more-plotting-py"><span class="std std-ref">More plotting tools from nilearn</span></a></span></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Nilearn comes with a set of plotting functions for easy visualization of Nifti-like images such..."><div class="figure" id="id5">
<img alt="../../_images/sphx_glr_plot_demo_plotting_thumb.png" src="../../_images/sphx_glr_plot_demo_plotting_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/01_plotting/plot_demo_plotting.html#sphx-glr-auto-examples-01-plotting-plot-demo-plotting-py"><span class="std std-ref">Plotting tools in nilearn</span></a></span></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="The `dim` argument controls the contrast of the background."><div class="figure" id="id6">
<img alt="../../_images/sphx_glr_plot_dim_plotting_thumb.png" src="../../_images/sphx_glr_plot_dim_plotting_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/01_plotting/plot_dim_plotting.html#sphx-glr-auto-examples-01-plotting-plot-dim-plotting-py"><span class="std std-ref">Controling the contrast of the background when plotting</span></a></span></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Visualizing a probablistic atlas requires visualizing the different maps that compose it."><div class="figure" id="id7">
<img alt="../../_images/sphx_glr_plot_overlay_thumb.png" src="../../_images/sphx_glr_plot_overlay_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/01_plotting/plot_overlay.html#sphx-glr-auto-examples-01-plotting-plot-overlay-py"><span class="std std-ref">Visualizing a probablistic atlas: the default mode in the MSDL atlas</span></a></span></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example does a simple but efficient decoding on the Haxby dataset: using a feature selecti..."><div class="figure" id="id8">
<img alt="../../_images/sphx_glr_plot_haxby_anova_svm_thumb.png" src="../../_images/sphx_glr_plot_haxby_anova_svm_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/02_decoding/plot_haxby_anova_svm.html#sphx-glr-auto-examples-02-decoding-plot-haxby-anova-svm-py"><span class="std std-ref">Decoding with ANOVA + SVM: face vs house in the Haxby dataset</span></a></span></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Here we compare different classifiers on a visual object recognition decoding task. "><div class="figure" id="id9">
<img alt="../../_images/sphx_glr_plot_haxby_different_estimators_thumb.png" src="../../_images/sphx_glr_plot_haxby_different_estimators_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/02_decoding/plot_haxby_different_estimators.html#sphx-glr-auto-examples-02-decoding-plot-haxby-different-estimators-py"><span class="std std-ref">Different classifiers in decoding the Haxby dataset</span></a></span></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Searchlight analysis requires fitting a classifier a large amount of times. As a result, it is ..."><div class="figure" id="id10">
<img alt="../../_images/sphx_glr_plot_haxby_searchlight_thumb.png" src="../../_images/sphx_glr_plot_haxby_searchlight_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/02_decoding/plot_haxby_searchlight.html#sphx-glr-auto-examples-02-decoding-plot-haxby-searchlight-py"><span class="std std-ref">Searchlight analysis of face vs house recognition</span></a></span></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Here is a simple example of decoding with a SpaceNet prior (i.e Graph-Net, TV-l1, etc.), reprod..."><div class="figure" id="id11">
<img alt="../../_images/sphx_glr_plot_haxby_space_net_thumb.png" src="../../_images/sphx_glr_plot_haxby_space_net_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/02_decoding/plot_haxby_space_net.html#sphx-glr-auto-examples-02-decoding-plot-haxby-space-net-py"><span class="std std-ref">Decoding with SpaceNet: face vs house object recognition</span></a></span></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="The segmenting power of SpaceNet is quite visible here."><div class="figure" id="id12">
<img alt="../../_images/sphx_glr_plot_mixed_gambles_space_net_thumb.png" src="../../_images/sphx_glr_plot_mixed_gambles_space_net_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/02_decoding/plot_mixed_gambles_space_net.html#sphx-glr-auto-examples-02-decoding-plot-mixed-gambles-space-net-py"><span class="std std-ref">SpaceNet on Jimura et al &#8220;mixed gambles&#8221; dataset.</span></a></span></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example partly reproduces the encoding model presented in     `Visual image reconstruction..."><div class="figure" id="id13">
<img alt="../../_images/sphx_glr_plot_miyawaki_encoding_thumb.png" src="../../_images/sphx_glr_plot_miyawaki_encoding_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/02_decoding/plot_miyawaki_encoding.html#sphx-glr-auto-examples-02-decoding-plot-miyawaki-encoding-py"><span class="std std-ref">Encoding models for visual stimuli from Miyawaki et al. 2008</span></a></span></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example uses Voxel-Based Morphometry (VBM) to study the relationship between aging and gra..."><div class="figure" id="id14">
<img alt="../../_images/sphx_glr_plot_oasis_vbm_thumb.png" src="../../_images/sphx_glr_plot_oasis_vbm_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/02_decoding/plot_oasis_vbm.html#sphx-glr-auto-examples-02-decoding-plot-oasis-vbm-py"><span class="std std-ref">Voxel-Based Morphometry on Oasis dataset</span></a></span></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Predicting age from gray-matter concentration maps from OASIS dataset. Note that age is a conti..."><div class="figure" id="id15">
<img alt="../../_images/sphx_glr_plot_oasis_vbm_space_net_thumb.png" src="../../_images/sphx_glr_plot_oasis_vbm_space_net_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/02_decoding/plot_oasis_vbm_space_net.html#sphx-glr-auto-examples-02-decoding-plot-oasis-vbm-space-net-py"><span class="std std-ref">Voxel-Based Morphometry on Oasis dataset with Space-Net prior</span></a></span></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="An example applying CanICA to resting-state data. This example applies it to 30 subjects of the..."><div class="figure" id="id16">
<img alt="../../_images/sphx_glr_plot_canica_resting_state_thumb.png" src="../../_images/sphx_glr_plot_canica_resting_state_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/03_connectivity/plot_canica_resting_state.html#sphx-glr-auto-examples-03-connectivity-plot-canica-resting-state-py"><span class="std std-ref">Group analysis of resting-state fMRI with ICA: CanICA</span></a></span></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example applies dictionary learning and ICA to resting-state data, visualizing resulting c..."><div class="figure" id="id17">
<img alt="../../_images/sphx_glr_plot_compare_resting_state_decomposition_thumb.png" src="../../_images/sphx_glr_plot_compare_resting_state_decomposition_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/03_connectivity/plot_compare_resting_state_decomposition.html#sphx-glr-auto-examples-03-connectivity-plot-compare-resting-state-decomposition-py"><span class="std std-ref">Dictionary Learning and ICA for doing group analysis of resting-state fMRI</span></a></span></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example shows how to use :class:`nilearn.regions.RegionExtractor` to extract spatially con..."><div class="figure" id="id18">
<img alt="../../_images/sphx_glr_plot_extract_regions_dictlearning_maps_thumb.png" src="../../_images/sphx_glr_plot_extract_regions_dictlearning_maps_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/03_connectivity/plot_extract_regions_dictlearning_maps.html#sphx-glr-auto-examples-03-connectivity-plot-extract-regions-dictlearning-maps-py"><span class="std std-ref">Regions extraction using Dictionary Learning and functional connectomes</span></a></span></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example shows how to produce seed-to-voxel correlation maps for a single subject based on ..."><div class="figure" id="id19">
<img alt="../../_images/sphx_glr_plot_seed_to_voxel_correlation_thumb.png" src="../../_images/sphx_glr_plot_seed_to_voxel_correlation_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/03_connectivity/plot_seed_to_voxel_correlation.html#sphx-glr-auto-examples-03-connectivity-plot-seed-to-voxel-correlation-py"><span class="std std-ref">Producing single subject maps of seed-to-voxel correlation</span></a></span></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="The goal of this example is to illustrate the use of the function :func:`nilearn.image.math_img..."><div class="figure" id="id20">
<img alt="../../_images/sphx_glr_plot_compare_mean_image_thumb.png" src="../../_images/sphx_glr_plot_compare_mean_image_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/04_manipulating_images/plot_compare_mean_image.html#sphx-glr-auto-examples-04-manipulating-images-plot-compare-mean-image-py"><span class="std std-ref">Comparing the means of 2 images</span></a></span></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This simple example shows how to extract regions from Smith atlas resting state networks."><div class="figure" id="id21">
<img alt="../../_images/sphx_glr_plot_extract_rois_smith_atlas_thumb.png" src="../../_images/sphx_glr_plot_extract_rois_smith_atlas_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/04_manipulating_images/plot_extract_rois_smith_atlas.html#sphx-glr-auto-examples-04-manipulating-images-plot-extract-rois-smith-atlas-py"><span class="std std-ref">Regions Extraction of Default Mode Networks using Smith Atlas</span></a></span></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example shows how to extract regions or separate the regions from a statistical map."><div class="figure" id="id22">
<img alt="../../_images/sphx_glr_plot_extract_rois_statistical_maps_thumb.png" src="../../_images/sphx_glr_plot_extract_rois_statistical_maps_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/04_manipulating_images/plot_extract_rois_statistical_maps.html#sphx-glr-auto-examples-04-manipulating-images-plot-extract-rois-statistical-maps-py"><span class="std std-ref">Region Extraction using a t-statistical map (3D)</span></a></span></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="The goal of this example is to illustrate the use of the function :func:`nilearn.image.math_img..."><div class="figure" id="id23">
<img alt="../../_images/sphx_glr_plot_negate_image_thumb.png" src="../../_images/sphx_glr_plot_negate_image_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/04_manipulating_images/plot_negate_image.html#sphx-glr-auto-examples-04-manipulating-images-plot-negate-image-py"><span class="std std-ref">Negating an image with math_img</span></a></span></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Here is a simple example of automatic mask computation using the nifti masker. The mask is comp..."><div class="figure" id="id24">
<img alt="../../_images/sphx_glr_plot_nifti_simple_thumb.png" src="../../_images/sphx_glr_plot_nifti_simple_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/04_manipulating_images/plot_nifti_simple.html#sphx-glr-auto-examples-04-manipulating-images-plot-nifti-simple-py"><span class="std std-ref">Simple example of NiftiMasker use</span></a></span></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="The goal of this example is to illustrate the use of the function :func:`nilearn.image.resample..."><div class="figure" id="id25">
<img alt="../../_images/sphx_glr_plot_resample_to_template_thumb.png" src="../../_images/sphx_glr_plot_resample_to_template_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/04_manipulating_images/plot_resample_to_template.html#sphx-glr-auto-examples-04-manipulating-images-plot-resample-to-template-py"><span class="std std-ref">Resample an image to a template</span></a></span></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example shows manual steps to create and further modify an ROI spatial mask. They represen..."><div class="figure" id="id26">
<img alt="../../_images/sphx_glr_plot_roi_extraction_thumb.png" src="../../_images/sphx_glr_plot_roi_extraction_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/04_manipulating_images/plot_roi_extraction.html#sphx-glr-auto-examples-04-manipulating-images-plot-roi-extraction-py"><span class="std std-ref">Computing a Region of Interest (ROI) mask manually</span></a></span></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="A permuted Ordinary Least Squares algorithm is run at each voxel in order to detemine whether o..."><div class="figure" id="id27">
<img alt="../../_images/sphx_glr_plot_haxby_mass_univariate_thumb.png" src="../../_images/sphx_glr_plot_haxby_mass_univariate_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/05_advanced/plot_haxby_mass_univariate.html#sphx-glr-auto-examples-05-advanced-plot-haxby-mass-univariate-py"><span class="std std-ref">Massively univariate analysis of face vs house recognition</span></a></span></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example shows how to download statistical maps from NeuroVault, label them with NeuroSynth..."><div class="figure" id="id28">
<img alt="../../_images/sphx_glr_plot_ica_neurovault_thumb.png" src="../../_images/sphx_glr_plot_ica_neurovault_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/05_advanced/plot_ica_neurovault.html#sphx-glr-auto-examples-05-advanced-plot-ica-neurovault-py"><span class="std std-ref">NeuroVault cross-study ICA maps.</span></a></span></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip=" This example is meant to demonstrate nilearn as a low-level tools used to combine feature extr..."><div class="figure" id="id29">
<img alt="../../_images/sphx_glr_plot_ica_resting_state_thumb.png" src="../../_images/sphx_glr_plot_ica_resting_state_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/05_advanced/plot_ica_resting_state.html#sphx-glr-auto-examples-05-advanced-plot-ica-resting-state-py"><span class="std std-ref">Multivariate decompositions: Independent component analysis of fMRI</span></a></span></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example shows the results obtained in a massively univariate analysis performed at the int..."><div class="figure" id="id30">
<img alt="../../_images/sphx_glr_plot_localizer_mass_univariate_methods_thumb.png" src="../../_images/sphx_glr_plot_localizer_mass_univariate_methods_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/05_advanced/plot_localizer_mass_univariate_methods.html#sphx-glr-auto-examples-05-advanced-plot-localizer-mass-univariate-methods-py"><span class="std std-ref">Massively univariate analysis of a motor task from the Localizer dataset</span></a></span></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example shows how to use the Localizer dataset in a basic analysis. A standard Anova is pe..."><div class="figure" id="id31">
<img alt="../../_images/sphx_glr_plot_localizer_simple_analysis_thumb.png" src="../../_images/sphx_glr_plot_localizer_simple_analysis_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/05_advanced/plot_localizer_simple_analysis.html#sphx-glr-auto-examples-05-advanced-plot-localizer-simple-analysis-py"><span class="std std-ref">Massively univariate analysis of a calculation task from the Localizer dataset</span></a></span></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example shows how to download statistical maps from NeuroVault"><div class="figure" id="id32">
<img alt="../../_images/sphx_glr_plot_neurovault_meta_analysis_thumb.png" src="../../_images/sphx_glr_plot_neurovault_meta_analysis_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/05_advanced/plot_neurovault_meta_analysis.html#sphx-glr-auto-examples-05-advanced-plot-neurovault-meta-analysis-py"><span class="std std-ref">NeuroVault meta-analysis of stop-go paradigm studies.</span></a></span></p>
</div>
</div><div style='clear:both'></div></div>
</div>


          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="nilearn.plotting.plot_glass_brain.html" title="7.10.9. nilearn.plotting.plot_glass_brain"
             >next</a></li>
        <li class="right" >
          <a href="nilearn.plotting.plot_roi.html" title="7.10.7. nilearn.plotting.plot_roi"
             >previous</a> |</li>
<li><a href="../../index.html">Nilearn Home</a> |&nbsp;</li>
<li><a href="../../user_guide.html">User Guide</a> |&nbsp;</li>
<li><a href="../../auto_examples/index.html">Examples</a> |&nbsp;</li>
<li><a href="../reference.html">Reference</a> |&nbsp;</li>
<li id="navbar-about"><a href="../../authors.html">About</a>|&nbsp;</li>
<li id="navbar-ecosystem"><a href="http://www.nipy.org/">Nipy ecosystem</a></li>

          <li class="nav-item nav-item-1"><a href="../../user_guide.html" >User guide: table of contents</a> &#187;</li>
          <li class="nav-item nav-item-2"><a href="../reference.html" >7. Reference documentation: all nilearn functions</a> &#187;</li> 
      </ul>
    </div>
    <div class="footer">
            &copy; The nilearn developers 2010-2015.
          Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 1.5.6.
        <span style="padding-left: 5ex;">
          <a href="../../_sources/modules/generated/nilearn.plotting.plot_stat_map.rst.txt"
        	 rel="nofollow">Show this page source</a>
        </span>
    </div>
  </body>
</html>