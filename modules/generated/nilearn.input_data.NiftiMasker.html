
<!DOCTYPE html>


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Nilearn: Machine learning for NeuroImaging in Python &mdash; Machine learning for NeuroImaging</title>
    
    <link rel="stylesheet" href="../../_static/nature.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/gallery.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../../',
        VERSION:     '0.2.5',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../_static/doctools.js"></script>
    <script type="text/javascript" src="../../_static/copybutton.js"></script>
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
    <link rel="top" title="Machine learning for NeuroImaging" href="../../index.html" />
    <link rel="up" title="7. Reference documentation: all nilearn functions" href="../reference.html" />
    <link rel="next" title="7.6.2. nilearn.input_data.MultiNiftiMasker" href="nilearn.input_data.MultiNiftiMasker.html" />
    <link rel="prev" title="7.5.17. nilearn.image.threshold_img" href="nilearn.image.threshold_img.html" />
<meta content="True" name="HandheldFriendly">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0">
<meta name="keywords" content="nilearn, neuroimaging, python, neuroscience, machinelearning">
<script type="text/javascript">
$(function () {
    // Lock the table of content to a fixed position once we scroll enough
    var top = 105 + $('.sphinxsidebarwrapper').offset().top - parseFloat($('.sphinxsidebarwrapper').css('margin-top').replace(/auto/, 0)),
        sections = {},
        i        = 0,
	url	 = document.URL.replace(/#.*$/, ""),
	current_section = 0;

    // Grab positions of our sections
    $('.headerlink').each(function(){
        sections[this.href.replace(url, '')] = $(this).offset().top - 50;
    });

    $(window).scroll(function(event) {
	var pos   = $(window).scrollTop();
	// Lock the table of content to a fixed position once we scroll enough
	if(pos > top){
	    //begin to scroll
	    $('.sphinxsidebarwrapper').css("position", "fixed");
	    $('.sphinxsidebarwrapper').css("top", -105);
	}
	else{
	    //lock it back into place
	    $('.sphinxsidebarwrapper').css("position", "relative");
	    $('.sphinxsidebarwrapper').css("top",0);
	}

	// Highlight the current section
	$('a.internal').removeClass('active');
        for(i in sections){
            if(sections[i] > pos){
		break;
            };
	    if($('a.internal[href$="' + i + '"]').is(':visible')){
		current_section = i;
	    };
        }
	$('a.internal[href$="' + current_section + '"]').addClass('active');
    });

});
</script>


<script type="text/javascript">

        var _gaq = _gaq || [];
        _gaq.push(['_setAccount', 'UA-41920728-1']);
        _gaq.push(['_trackPageview']);

        (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
        })();
    </script>

  </head>
  <body>
<div id="logo-banner">
  <div class="logo">
    <a href="../../index.html">
      <img src="../../_static/nilearn-logo.png" alt="Nilearn logo"  border="0" />
    </a>
  </div>
  <!-- A tag cloud to make it easy for people to find what they are
                         looking for -->
 <div class="tags">
  <ul>
    <li>
      <big><a href="../../auto_examples/decoding/plot_haxby_anova_svm.html">SVM</a></big>
    </li>
    <li>
      <small><a href="../../connectivity/parcellating.html">Ward
          clustering</a></small>
    </li>
    <li>
      <a href="../../decoding/searchlight.html">Searchlight</a>
    </li>
    <li>
      <big><a href="../../connectivity/resting_state_networks.html">ICA</a></big>
    </li>
    <li>
      <a href="../../manipulating_images/data_preparation.html">Nifti IO</a>
    </li>
    <li>
      <a href="../reference.html#module-nilearn.datasets">Datasets</a>
    </li>
  </ul>
 </div>

  <div class="banner">
    <h1>Nilearn:</h1>
    <h2>Machine learning for Neuro-Imaging in Python</h2>
  </div>
  <div class="search_form">
    <div id="cse" style="width: 100%;"></div>
    <script src="http://www.google.com/jsapi" type="text/javascript"></script>
    <script type="text/javascript">
      google.load('search', '1', {language : 'en'});
      google.setOnLoadCallback(function() {
      var customSearchControl = new google.search.CustomSearchControl('014136483057745874622:r-npolb1uki');
      customSearchControl.setResultSetSize(google.search.Search.FILTERED_CSE_RESULTSET);
      var options = new google.search.DrawOptions();
      options.setAutoComplete(true);
      customSearchControl.draw('cse', options);
      }, true);
    </script>
  </div>
</div>



    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="nilearn.input_data.MultiNiftiMasker.html" title="7.6.2. nilearn.input_data.MultiNiftiMasker"
             accesskey="N">next</a></li>
        <li class="right" >
          <a href="nilearn.image.threshold_img.html" title="7.5.17. nilearn.image.threshold_img"
             accesskey="P">previous</a> |</li>
<li><a href="../../index.html">Nilearn Home</a> |&nbsp;</li>
<li><a href="../../user_guide.html">User Guide</a> |&nbsp;</li>
<li><a href="../../auto_examples/index.html">Examples</a> |&nbsp;</li>
<li><a href="../reference.html">Reference</a> |&nbsp;</li>
<li id="navbar-about"><a href="../../authors.html">About</a>|&nbsp;</li>
<li id="navbar-ecosystem"><a href="http://www.nipy.org/">Nipy ecosystem</a></li>

          <li><a href="../../user_guide.html" >User guide: table of contents</a> &raquo;</li>
          <li><a href="../reference.html" accesskey="U">7. Reference documentation: all nilearn functions</a> &raquo;</li> 
      </ul>
    </div>
      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">


<h4> Giving credit </h4>
  <ul class="simple">
    <li><p>Please consider <a href="../../authors.html#citing">citing the
                    papers</a>.</p></li>
  </ul>

  <h3><a href="../../index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">7.6.1. nilearn.input_data.NiftiMasker</a><ul>
<li><a class="reference internal" href="#examples-using-nilearn-input-data-niftimasker">7.6.1.1. Examples using <tt class="docutils literal"><span class="pre">nilearn.input_data.NiftiMasker</span></tt></a></li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="nilearn.image.threshold_img.html"
                        title="previous chapter">7.5.17. nilearn.image.threshold_img</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="nilearn.input_data.MultiNiftiMasker.html"
                        title="next chapter">7.6.2. nilearn.input_data.MultiNiftiMasker</a></p>

<div class="navbar">
</div> <!-- end navbar -->

<script type="text/javascript">$('#searchbox-ml').show(0);</script>
<script type="text/javascript">$('#searchbox-site').show(0);</script>


        </div>
      </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">This page is a reference documentation. It only explains the class
signature, and not how to use it. Please refer to the
<a class="reference internal" href="../../user_guide.html#user-guide"><em>user guide</em></a> for the big picture.</p>
</div>
<div class="section" id="nilearn-input-data-niftimasker">
<h1>7.6.1. nilearn.input_data.NiftiMasker<a class="headerlink" href="#nilearn-input-data-niftimasker" title="Permalink to this headline">¶</a></h1>
<dl class="class">
<dt id="nilearn.input_data.NiftiMasker">
<em class="property">class </em><tt class="descclassname">nilearn.input_data.</tt><tt class="descname">NiftiMasker</tt><big>(</big><em>mask_img=None</em>, <em>sessions=None</em>, <em>smoothing_fwhm=None</em>, <em>standardize=False</em>, <em>detrend=False</em>, <em>low_pass=None</em>, <em>high_pass=None</em>, <em>t_r=None</em>, <em>target_affine=None</em>, <em>target_shape=None</em>, <em>mask_strategy='background'</em>, <em>mask_args=None</em>, <em>sample_mask=None</em>, <em>memory_level=1</em>, <em>memory=Memory(cachedir=None)</em>, <em>verbose=0</em><big>)</big><a class="headerlink" href="#nilearn.input_data.NiftiMasker" title="Permalink to this definition">¶</a></dt>
<dd><p>Class for masking of Niimg-like objects.</p>
<p>NiftiMasker is useful when preprocessing (detrending, standardization,
resampling, etc.) of in-mask voxels is necessary. Use case: working with
time series of resting-state or task maps.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>mask_img</strong> : Niimg-like object, optional</p>
<blockquote>
<div><p>See <a class="reference external" href="http://nilearn.github.io/manipulating_images/input_output.html">http://nilearn.github.io/manipulating_images/input_output.html</a>.
Mask for the data. If not given, a mask is computed in the fit step.
Optional parameters (mask_args and mask_strategy) can be set to
fine tune the mask extraction.</p>
</div></blockquote>
<p><strong>sessions</strong> : numpy array, optional</p>
<blockquote>
<div><p>Add a session level to the preprocessing. Each session will be
detrended independently. Must be a 1D array of n_samples elements.</p>
</div></blockquote>
<p><strong>smoothing_fwhm</strong> : float, optional</p>
<blockquote>
<div><p>If smoothing_fwhm is not None, it gives the full-width half maximum in
millimeters of the spatial smoothing to apply to the signal.</p>
</div></blockquote>
<p><strong>standardize</strong> : boolean, optional</p>
<blockquote>
<div><p>If standardize is True, the time-series are centered and normed:
their mean is put to 0 and their variance to 1 in the time dimension.</p>
</div></blockquote>
<p><strong>detrend</strong> : boolean, optional</p>
<blockquote>
<div><p>This parameter is passed to signal.clean. Please see the related
documentation for details</p>
</div></blockquote>
<p><strong>low_pass</strong> : False or float, optional</p>
<blockquote>
<div><p>This parameter is passed to signal.clean. Please see the related
documentation for details</p>
</div></blockquote>
<p><strong>high_pass</strong> : False or float, optional</p>
<blockquote>
<div><p>This parameter is passed to signal.clean. Please see the related
documentation for details</p>
</div></blockquote>
<p><strong>t_r</strong> : float, optional</p>
<blockquote>
<div><p>This parameter is passed to signal.clean. Please see the related
documentation for details</p>
</div></blockquote>
<p><strong>target_affine</strong> : 3x3 or 4x4 matrix, optional</p>
<blockquote>
<div><p>This parameter is passed to image.resample_img. Please see the
related documentation for details.</p>
</div></blockquote>
<p><strong>target_shape</strong> : 3-tuple of integers, optional</p>
<blockquote>
<div><p>This parameter is passed to image.resample_img. Please see the
related documentation for details.</p>
</div></blockquote>
<p><strong>mask_strategy: {&#8216;background&#8217; or &#8216;epi&#8217;}, optional</strong></p>
<blockquote>
<div><p>The strategy used to compute the mask: use &#8216;background&#8217; if your
images present a clear homogeneous background, and &#8216;epi&#8217; if they
are raw EPI images. Depending on this value, the mask will be
computed from masking.compute_background_mask or
masking.compute_epi_mask. Default is &#8216;background&#8217;.</p>
</div></blockquote>
<p><strong>mask_args</strong> : dict, optional</p>
<blockquote>
<div><p>If mask is None, these are additional parameters passed to
masking.compute_background_mask or masking.compute_epi_mask
to fine-tune mask computation. Please see the related documentation
for details.</p>
</div></blockquote>
<p><strong>sample_mask</strong> : Any type compatible with numpy-array indexing</p>
<blockquote>
<div><p>Masks the niimgs along time/fourth dimension. This complements
3D masking by the mask_img argument. This masking step is applied
before data preprocessing at the beginning of NiftiMasker.transform.
This is useful to perform data subselection as part of a scikit-learn
pipeline.</p>
</div></blockquote>
<p><strong>memory</strong> : instance of joblib.Memory or string</p>
<blockquote>
<div><p>Used to cache the masking process.
By default, no caching is done. If a string is given, it is the
path to the caching directory.</p>
</div></blockquote>
<p><strong>memory_level</strong> : integer, optional</p>
<blockquote>
<div><p>Rough estimator of the amount of memory used by caching. Higher value
means more memory for caching.</p>
</div></blockquote>
<p><strong>verbose</strong> : integer, optional</p>
<blockquote class="last">
<div><p>Indicate the level of verbosity. By default, nothing is printed</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
<div class="admonition seealso">
<p class="first admonition-title">See also</p>
<p class="last"><a class="reference internal" href="nilearn.masking.compute_background_mask.html#nilearn.masking.compute_background_mask" title="nilearn.masking.compute_background_mask"><tt class="xref py py-obj docutils literal"><span class="pre">nilearn.masking.compute_background_mask</span></tt></a>, <a class="reference internal" href="nilearn.masking.compute_epi_mask.html#nilearn.masking.compute_epi_mask" title="nilearn.masking.compute_epi_mask"><tt class="xref py py-obj docutils literal"><span class="pre">nilearn.masking.compute_epi_mask</span></tt></a>, <a class="reference internal" href="nilearn.image.resample_img.html#nilearn.image.resample_img" title="nilearn.image.resample_img"><tt class="xref py py-obj docutils literal"><span class="pre">nilearn.image.resample_img</span></tt></a>, <a class="reference internal" href="nilearn.masking.apply_mask.html#nilearn.masking.apply_mask" title="nilearn.masking.apply_mask"><tt class="xref py py-obj docutils literal"><span class="pre">nilearn.masking.apply_mask</span></tt></a>, <a class="reference internal" href="nilearn.signal.clean.html#nilearn.signal.clean" title="nilearn.signal.clean"><tt class="xref py py-obj docutils literal"><span class="pre">nilearn.signal.clean</span></tt></a></p>
</div>
<p class="rubric">Attributes</p>
<table border="1" class="docutils">
<colgroup>
<col width="15%" />
<col width="85%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><cite>mask_img_</cite></td>
<td>(nibabel.Nifti1Image) The mask of the data, or the computed one.</td>
</tr>
<tr class="row-even"><td><cite>affine_</cite></td>
<td>(4x4 numpy array) Affine of the transformed image.</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="nilearn.input_data.NiftiMasker.__init__">
<tt class="descname">__init__</tt><big>(</big><em>mask_img=None</em>, <em>sessions=None</em>, <em>smoothing_fwhm=None</em>, <em>standardize=False</em>, <em>detrend=False</em>, <em>low_pass=None</em>, <em>high_pass=None</em>, <em>t_r=None</em>, <em>target_affine=None</em>, <em>target_shape=None</em>, <em>mask_strategy='background'</em>, <em>mask_args=None</em>, <em>sample_mask=None</em>, <em>memory_level=1</em>, <em>memory=Memory(cachedir=None)</em>, <em>verbose=0</em><big>)</big><a class="headerlink" href="#nilearn.input_data.NiftiMasker.__init__" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nilearn.input_data.NiftiMasker.fit">
<tt class="descname">fit</tt><big>(</big><em>imgs=None</em>, <em>y=None</em><big>)</big><a class="headerlink" href="#nilearn.input_data.NiftiMasker.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the mask corresponding to the data</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>imgs: list of Niimg-like objects</strong></p>
<blockquote class="last">
<div><p>See <a class="reference external" href="http://nilearn.github.io/manipulating_images/input_output.html">http://nilearn.github.io/manipulating_images/input_output.html</a>.
Data on which the mask must be calculated. If this is a list,
the affine is considered the same for all.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nilearn.input_data.NiftiMasker.fit_transform">
<tt class="descname">fit_transform</tt><big>(</big><em>X</em>, <em>y=None</em>, <em>confounds=None</em>, <em>**fit_params</em><big>)</big><a class="headerlink" href="#nilearn.input_data.NiftiMasker.fit_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit to data, then transform it</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>X</strong> : Niimg-like object</p>
<blockquote>
<div><p>See <a class="reference external" href="http://nilearn.github.io/manipulating_images/input_output.html">http://nilearn.github.io/manipulating_images/input_output.html</a>.</p>
</div></blockquote>
<p><strong>y</strong> : numpy array of shape [n_samples]</p>
<blockquote>
<div><p>Target values.</p>
</div></blockquote>
<p><strong>confounds: list of confounds, optional</strong></p>
<blockquote>
<div><p>List of confounds (2D arrays or filenames pointing to CSV
files). Must be of same length than imgs_list.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>X_new</strong> : numpy array of shape [n_samples, n_features_new]</p>
<blockquote class="last">
<div><p>Transformed array.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nilearn.input_data.NiftiMasker.get_params">
<tt class="descname">get_params</tt><big>(</big><em>deep=True</em><big>)</big><a class="headerlink" href="#nilearn.input_data.NiftiMasker.get_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Get parameters for this estimator.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>deep: boolean, optional</strong></p>
<blockquote>
<div><p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>params</strong> : mapping of string to any</p>
<blockquote class="last">
<div><p>Parameter names mapped to their values.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nilearn.input_data.NiftiMasker.inverse_transform">
<tt class="descname">inverse_transform</tt><big>(</big><em>X</em><big>)</big><a class="headerlink" href="#nilearn.input_data.NiftiMasker.inverse_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Transform the 2D data matrix back to an image in brain space.</p>
</dd></dl>

<dl class="method">
<dt id="nilearn.input_data.NiftiMasker.set_params">
<tt class="descname">set_params</tt><big>(</big><em>**params</em><big>)</big><a class="headerlink" href="#nilearn.input_data.NiftiMasker.set_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The former have parameters of the form
<tt class="docutils literal"><span class="pre">&lt;component&gt;__&lt;parameter&gt;</span></tt> so that it&#8217;s possible to update each
component of a nested object.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">self</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nilearn.input_data.NiftiMasker.transform">
<tt class="descname">transform</tt><big>(</big><em>imgs</em>, <em>confounds=None</em><big>)</big><a class="headerlink" href="#nilearn.input_data.NiftiMasker.transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply mask, spatial and temporal preprocessing</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>imgs: 3D/4D Niimg-like object</strong></p>
<blockquote>
<div><p>See <a class="reference external" href="http://nilearn.github.io/manipulating_images/input_output.html">http://nilearn.github.io/manipulating_images/input_output.html</a>.
Images to process. It must boil down to a 4D image with scans
number as last dimension.</p>
</div></blockquote>
<p><strong>confounds: CSV file or array-like, optional</strong></p>
<blockquote>
<div><p>This parameter is passed to signal.clean. Please see the related
documentation for details.
shape: (number of scans, number of confounds)</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">region_signals: 2D numpy.ndarray</p>
<blockquote class="last">
<div><p>Signal for each element.
shape: (number of scans, number of elements)</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nilearn.input_data.NiftiMasker.transform_single_imgs">
<tt class="descname">transform_single_imgs</tt><big>(</big><em>imgs</em>, <em>confounds=None</em>, <em>copy=True</em><big>)</big><a class="headerlink" href="#nilearn.input_data.NiftiMasker.transform_single_imgs" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply mask, spatial and temporal preprocessing</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>imgs: 3D/4D Niimg-like object</strong></p>
<blockquote>
<div><p>See <a class="reference external" href="http://nilearn.github.io/manipulating_images/input_output.html">http://nilearn.github.io/manipulating_images/input_output.html</a>.
Images to process. It must boil down to a 4D image with scans
number as last dimension.</p>
</div></blockquote>
<p><strong>confounds: CSV file or array-like, optional</strong></p>
<blockquote>
<div><p>This parameter is passed to signal.clean. Please see the related
documentation for details.
shape: (number of scans, number of confounds)</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">region_signals: 2D numpy.ndarray</p>
<blockquote class="last">
<div><p>Signal for each voxel inside the mask.
shape: (number of scans, number of voxels)</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<div class="section" id="examples-using-nilearn-input-data-niftimasker">
<h2>7.6.1.1. Examples using <tt class="docutils literal"><span class="pre">nilearn.input_data.NiftiMasker</span></tt><a class="headerlink" href="#examples-using-nilearn-input-data-niftimasker" title="Permalink to this headline">¶</a></h2>
<div class="sphx-glr-thumbcontainer" tooltip="Here is a simple example of decoding, reproducing the Haxby 2001 study on a face vs cat discrim..."><div class="figure">
<img alt="../../_images/sphx_glr_plot_haxby_simple_thumb.png" src="../../_images/sphx_glr_plot_haxby_simple_thumb.png" />
<p class="caption"><a class="reference internal" href="../../auto_examples/plot_haxby_simple.html#sphx-glr-auto-examples-plot-haxby-simple-py"><em>Simple example of decoding: the Haxby data</em></a></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example does a simple but efficient decoding on the Haxby dataset: using a feature selecti..."><div class="figure">
<img alt="../../_images/sphx_glr_plot_haxby_anova_svm_thumb.png" src="../../_images/sphx_glr_plot_haxby_anova_svm_thumb.png" />
<p class="caption"><a class="reference internal" href="../../auto_examples/02_decoding/plot_haxby_anova_svm.html#sphx-glr-auto-examples-02-decoding-plot-haxby-anova-svm-py"><em>The Haxby dataset: face vs house in object recognition</em></a></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Here we compare different classifiers on a visual object recognition decoding task. "><div class="figure">
<img alt="../../_images/sphx_glr_plot_haxby_different_estimators_thumb.png" src="../../_images/sphx_glr_plot_haxby_different_estimators_thumb.png" />
<p class="caption"><a class="reference internal" href="../../auto_examples/02_decoding/plot_haxby_different_estimators.html#sphx-glr-auto-examples-02-decoding-plot-haxby-different-estimators-py"><em>Different classifiers in decoding the Haxby dataset</em></a></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="In this script we reproduce the data analysis conducted by Haxby et al. in "Distributed and Ove..."><div class="figure">
<img alt="../../_images/sphx_glr_plot_haxby_full_analysis_thumb.png" src="../../_images/sphx_glr_plot_haxby_full_analysis_thumb.png" />
<p class="caption"><a class="reference internal" href="../../auto_examples/02_decoding/plot_haxby_full_analysis.html#sphx-glr-auto-examples-02-decoding-plot-haxby-full-analysis-py"><em>ROI-based decoding analysis in Haxby et al. dataset</em></a></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Here we set the number of features selected in an Anova-SVC approach to maximize the cross-vali..."><div class="figure">
<img alt="../../_images/sphx_glr_plot_haxby_grid_search_thumb.png" src="../../_images/sphx_glr_plot_haxby_grid_search_thumb.png" />
<p class="caption"><a class="reference internal" href="../../auto_examples/02_decoding/plot_haxby_grid_search.html#sphx-glr-auto-examples-02-decoding-plot-haxby-grid-search-py"><em>Setting a parameter by cross-validation</em></a></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="We compare one vs all and one vs one multi-class strategies: the overall cross-validated accura..."><div class="figure">
<img alt="../../_images/sphx_glr_plot_haxby_multiclass_thumb.png" src="../../_images/sphx_glr_plot_haxby_multiclass_thumb.png" />
<p class="caption"><a class="reference internal" href="../../auto_examples/02_decoding/plot_haxby_multiclass.html#sphx-glr-auto-examples-02-decoding-plot-haxby-multiclass-py"><em>The haxby dataset: different multi-class strategies</em></a></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Searchlight analysis requires fitting a classifier a large amount of times. As a result, it is ..."><div class="figure">
<img alt="../../_images/sphx_glr_plot_haxby_searchlight_thumb.png" src="../../_images/sphx_glr_plot_haxby_searchlight_thumb.png" />
<p class="caption"><a class="reference internal" href="../../auto_examples/02_decoding/plot_haxby_searchlight.html#sphx-glr-auto-examples-02-decoding-plot-haxby-searchlight-py"><em>Searchlight analysis of face vs house recognition</em></a></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example uses Voxel-Based Morphometry (VBM) to study the relationship between aging and gra..."><div class="figure">
<img alt="../../_images/sphx_glr_plot_oasis_vbm_thumb.png" src="../../_images/sphx_glr_plot_oasis_vbm_thumb.png" />
<p class="caption"><a class="reference internal" href="../../auto_examples/02_decoding/plot_oasis_vbm.html#sphx-glr-auto-examples-02-decoding-plot-oasis-vbm-py"><em>Voxel-Based Morphometry on Oasis dataset</em></a></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="We use spatially-constrained Ward-clustering to create a set of parcels. These parcels are part..."><div class="figure">
<img alt="../../_images/sphx_glr_plot_rest_clustering_thumb.png" src="../../_images/sphx_glr_plot_rest_clustering_thumb.png" />
<p class="caption"><a class="reference internal" href="../../auto_examples/03_connectivity/plot_rest_clustering.html#sphx-glr-auto-examples-03-connectivity-plot-rest-clustering-py"><em>Ward clustering to learn a brain parcellation from rest fMRI</em></a></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example shows how to produce seed-based correlation maps for a single subject based on res..."><div class="figure">
<img alt="../../_images/sphx_glr_plot_seed_based_correlation_thumb.png" src="../../_images/sphx_glr_plot_seed_based_correlation_thumb.png" />
<p class="caption"><a class="reference internal" href="../../auto_examples/03_connectivity/plot_seed_based_correlation.html#sphx-glr-auto-examples-03-connectivity-plot-seed-based-correlation-py"><em>Producing single subject maps of seed-based correlation</em></a></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="In this example, the Nifti masker is used to automatically compute a mask."><div class="figure">
<img alt="../../_images/sphx_glr_plot_mask_computation_thumb.png" src="../../_images/sphx_glr_plot_mask_computation_thumb.png" />
<p class="caption"><a class="reference internal" href="../../auto_examples/04_manipulating_images/plot_mask_computation.html#sphx-glr-auto-examples-04-manipulating-images-plot-mask-computation-py"><em>Understanding NiftiMasker and mask computation</em></a></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Here is a simple example of automatic mask computation using the nifti masker. The mask is comp..."><div class="figure">
<img alt="../../_images/sphx_glr_plot_nifti_simple_thumb.png" src="../../_images/sphx_glr_plot_nifti_simple_thumb.png" />
<p class="caption"><a class="reference internal" href="../../auto_examples/04_manipulating_images/plot_nifti_simple.html#sphx-glr-auto-examples-04-manipulating-images-plot-nifti-simple-py"><em>Simple example of NiftiMasker use</em></a></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="A permuted Ordinary Least Squares algorithm is run at each voxel in order to detemine whether o..."><div class="figure">
<img alt="../../_images/sphx_glr_plot_haxby_mass_univariate_thumb.png" src="../../_images/sphx_glr_plot_haxby_mass_univariate_thumb.png" />
<p class="caption"><a class="reference internal" href="../../auto_examples/05_advanced/plot_haxby_mass_univariate.html#sphx-glr-auto-examples-05-advanced-plot-haxby-mass-univariate-py"><em>Massively univariate analysis of face vs house recognition</em></a></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip=" This example is meant to demonstrate nilearn as a low-level tools used to combine feature extr..."><div class="figure">
<img alt="../../_images/sphx_glr_plot_ica_resting_state_thumb.png" src="../../_images/sphx_glr_plot_ica_resting_state_thumb.png" />
<p class="caption"><a class="reference internal" href="../../auto_examples/05_advanced/plot_ica_resting_state.html#sphx-glr-auto-examples-05-advanced-plot-ica-resting-state-py"><em>Multivariate decompositions: Independent component analysis of fMRI</em></a></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example shows the results obtained in a massively univariate analysis performed at the int..."><div class="figure">
<img alt="../../_images/sphx_glr_plot_localizer_mass_univariate_methods_thumb.png" src="../../_images/sphx_glr_plot_localizer_mass_univariate_methods_thumb.png" />
<p class="caption"><a class="reference internal" href="../../auto_examples/05_advanced/plot_localizer_mass_univariate_methods.html#sphx-glr-auto-examples-05-advanced-plot-localizer-mass-univariate-methods-py"><em>Massively univariate analysis of a motor task from the Localizer dataset</em></a></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example shows how to use the Localizer dataset in a basic analysis. A standard Anova is pe..."><div class="figure">
<img alt="../../_images/sphx_glr_plot_localizer_simple_analysis_thumb.png" src="../../_images/sphx_glr_plot_localizer_simple_analysis_thumb.png" />
<p class="caption"><a class="reference internal" href="../../auto_examples/05_advanced/plot_localizer_simple_analysis.html#sphx-glr-auto-examples-05-advanced-plot-localizer-simple-analysis-py"><em>Massively univariate analysis of a calculation task from the Localizer dataset</em></a></p>
</div>
</div><div style='clear:both'></div></div>
</div>


          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="nilearn.input_data.MultiNiftiMasker.html" title="7.6.2. nilearn.input_data.MultiNiftiMasker"
             >next</a></li>
        <li class="right" >
          <a href="nilearn.image.threshold_img.html" title="7.5.17. nilearn.image.threshold_img"
             >previous</a> |</li>
<li><a href="../../index.html">Nilearn Home</a> |&nbsp;</li>
<li><a href="../../user_guide.html">User Guide</a> |&nbsp;</li>
<li><a href="../../auto_examples/index.html">Examples</a> |&nbsp;</li>
<li><a href="../reference.html">Reference</a> |&nbsp;</li>
<li id="navbar-about"><a href="../../authors.html">About</a>|&nbsp;</li>
<li id="navbar-ecosystem"><a href="http://www.nipy.org/">Nipy ecosystem</a></li>

          <li><a href="../../user_guide.html" >User guide: table of contents</a> &raquo;</li>
          <li><a href="../reference.html" >7. Reference documentation: all nilearn functions</a> &raquo;</li> 
      </ul>
    </div>
    <div class="footer">
            &copy; The nilearn developers 2010-2015.
          Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 1.2.3.
        <span style="padding-left: 5ex;">
          <a href="../../_sources/modules/generated/nilearn.input_data.NiftiMasker.txt"
        	 rel="nofollow">Show this page source</a>
        </span>
    </div>
  </body>
</html>