
<!DOCTYPE html>


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Nilearn: Machine learning for NeuroImaging in Python &mdash; Machine learning for NeuroImaging</title>
    
    <link rel="stylesheet" href="../_static/nature.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/gallery.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     '0.2.3',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="../_static/copybutton.js"></script>
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="top" title="Machine learning for NeuroImaging" href="../index.html" />
    <link rel="up" title="5. Image manipulation" href="index.html" />
    <link rel="next" title="6. Advanced usage: manual pipelines and scaling up" href="../building_blocks/index.html" />
    <link rel="prev" title="5.1. Data preparation: loading and basic signal extraction" href="data_preparation.html" />
<meta content="True" name="HandheldFriendly">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0">
<meta name="keywords" content="nilearn, neuroimaging, python, neuroscience, machinelearning">
<script type="text/javascript">
$(function () {
    // Lock the table of content to a fixed position once we scroll enough
    var top = 105 + $('.sphinxsidebarwrapper').offset().top - parseFloat($('.sphinxsidebarwrapper').css('margin-top').replace(/auto/, 0)),
        sections = {},
        i        = 0,
	url	 = document.URL.replace(/#.*$/, ""),
	current_section = 0;

    // Grab positions of our sections
    $('.headerlink').each(function(){
        sections[this.href.replace(url, '')] = $(this).offset().top - 50;
    });

    $(window).scroll(function(event) {
	var pos   = $(window).scrollTop();
	// Lock the table of content to a fixed position once we scroll enough
	if(pos > top){
	    //begin to scroll
	    $('.sphinxsidebarwrapper').css("position", "fixed");
	    $('.sphinxsidebarwrapper').css("top", -105);
	}
	else{
	    //lock it back into place
	    $('.sphinxsidebarwrapper').css("position", "relative");
	    $('.sphinxsidebarwrapper').css("top",0);
	}

	// Highlight the current section
	$('a.internal').removeClass('active');
        for(i in sections){
            if(sections[i] > pos){
		break;
            };
	    if($('a.internal[href$="' + i + '"]').is(':visible')){
		current_section = i;
	    };
        }
	$('a.internal[href$="' + current_section + '"]').addClass('active');
    });

});
</script>


<script type="text/javascript">

        var _gaq = _gaq || [];
        _gaq.push(['_setAccount', 'UA-41920728-1']);
        _gaq.push(['_trackPageview']);

        (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
        })();
    </script>

  </head>
  <body>
<div id="logo-banner">
  <div class="logo">
    <a href="../index.html">
      <img src="../_static/nilearn-logo.png" alt="Nilearn logo"  border="0" />
    </a>
  </div>
  <!-- A tag cloud to make it easy for people to find what they are
                         looking for -->
 <div class="tags">
  <ul>
    <li>
      <big><a href="../auto_examples/decoding/plot_haxby_anova_svm.html">SVM</a></big>
    </li>
    <li>
      <small><a href="../connectivity/parcellating.html">Ward
          clustering</a></small>
    </li>
    <li>
      <a href="../decoding/searchlight.html">Searchlight</a>
    </li>
    <li>
      <big><a href="../connectivity/resting_state_networks.html">ICA</a></big>
    </li>
    <li>
      <a href="../manipulating_visualizing/data_preparation.html">Nifti IO</a>
    </li>
    <li>
      <a href="../modules/reference.html#module-nilearn.datasets">Datasets</a>
    </li>
  </ul>
 </div>

  <div class="banner">
    <h1>Nilearn:</h1>
    <h2>Machine learning for Neuro-Imaging in Python</h2>
  </div>
  <div class="search_form">
    <div id="cse" style="width: 100%;"></div>
    <script src="http://www.google.com/jsapi" type="text/javascript"></script>
    <script type="text/javascript">
      google.load('search', '1', {language : 'en'});
      google.setOnLoadCallback(function() {
      var customSearchControl = new google.search.CustomSearchControl('014136483057745874622:r-npolb1uki');
      customSearchControl.setResultSetSize(google.search.Search.FILTERED_CSE_RESULTSET);
      var options = new google.search.DrawOptions();
      options.setAutoComplete(true);
      customSearchControl.draw('cse', options);
      }, true);
    </script>
  </div>
</div>



    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../building_blocks/index.html" title="6. Advanced usage: manual pipelines and scaling up"
             accesskey="N">next</a></li>
        <li class="right" >
          <a href="data_preparation.html" title="5.1. Data preparation: loading and basic signal extraction"
             accesskey="P">previous</a> |</li>
<li><a href="../index.html">Nilearn Home</a> |&nbsp;</li>
<li><a href="../user_guide.html">User Guide</a> |&nbsp;</li>
<li><a href="../auto_examples/index.html">Examples</a> |&nbsp;</li>
<li><a href="../modules/reference.html">Reference</a> |&nbsp;</li>
<li id="navbar-about"><a href="../authors.html">About</a>|&nbsp;</li>
<li id="navbar-ecosystem"><a href="http://www.nipy.org/">Nipy ecosystem</a></li>

          <li><a href="../user_guide.html" >User guide: table of contents</a> &raquo;</li>
          <li><a href="index.html" accesskey="U">5. Image manipulation</a> &raquo;</li> 
      </ul>
    </div>
      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">


<h4> Giving credit </h4>
  <ul class="simple">
    <li><p>Please consider <a href="../authors.html#citing">citing the
                    papers</a>.</p></li>
  </ul>

  <h3><a href="../index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">5.2. Manipulating brain volume: input/output, masking, ROIs, smoothing...</a><ul>
<li><a class="reference internal" href="#loading-data">5.2.1. Loading data</a><ul>
<li><a class="reference internal" href="#fetching-open-datasets">5.2.1.1. Fetching open datasets</a></li>
<li><a class="reference internal" href="#loading-your-own-data">5.2.1.2. Loading your own data</a></li>
</ul>
</li>
<li><a class="reference internal" href="#understanding-neuroimaging-data">5.2.2. Understanding neuroimaging data</a><ul>
<li><a class="reference internal" href="#nifti-and-analyze-files">5.2.2.1. Nifti and Analyze files</a></li>
<li><a class="reference internal" href="#niimg-like-objects">5.2.2.2. Niimg-like objects</a></li>
<li><a class="reference internal" href="#text-files-phenotype-or-behavior">5.2.2.3. Text files: phenotype or behavior</a></li>
</ul>
</li>
<li><a class="reference internal" href="#masking-data-manually">5.2.3. Masking data manually</a><ul>
<li><a class="reference internal" href="#extracting-a-brain-mask">5.2.3.1. Extracting a brain mask</a></li>
<li><a class="reference internal" href="#from-4d-nifti-images-to-2d-data-arrays">5.2.3.2. From 4D Nifti images to 2D data arrays</a></li>
</ul>
</li>
<li><a class="reference internal" href="#functions-for-data-preparation-steps">5.2.4. Functions for data preparation steps</a></li>
<li><a class="reference internal" href="#image-operations-creating-a-roi-mask-manually">5.2.5. Image operations: creating a ROI mask manually</a><ul>
<li><a class="reference internal" href="#smoothing">5.2.5.1. Smoothing</a></li>
<li><a class="reference internal" href="#selecting-features">5.2.5.2. Selecting features</a></li>
<li><a class="reference internal" href="#thresholding">5.2.5.3. Thresholding</a></li>
<li><a class="reference internal" href="#mask-intersection">5.2.5.4. Mask intersection</a></li>
<li><a class="reference internal" href="#mask-dilation">5.2.5.5. Mask dilation</a></li>
<li><a class="reference internal" href="#extracting-connected-components">5.2.5.6. Extracting connected components</a></li>
<li><a class="reference internal" href="#saving-the-result">5.2.5.7. Saving the result</a></li>
</ul>
</li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="data_preparation.html"
                        title="previous chapter">5.1. Data preparation: loading and basic signal extraction</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="../building_blocks/index.html"
                        title="next chapter">6. Advanced usage: manual pipelines and scaling up</a></p>

<div class="navbar">
</div> <!-- end navbar -->

<script type="text/javascript">$('#searchbox-ml').show(0);</script>
<script type="text/javascript">$('#searchbox-site').show(0);</script>


        </div>
      </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="manipulating-brain-volume-input-output-masking-rois-smoothing">
<span id="data-manipulation"></span><h1>5.2. Manipulating brain volume: input/output, masking, ROIs, smoothing...<a class="headerlink" href="#manipulating-brain-volume-input-output-masking-rois-smoothing" title="Permalink to this headline">¶</a></h1>
<p>This chapter introduces the data structure of brain images and tools to
manipulation these.</p>
<div class="contents local topic" id="chapters-contents">
<p class="topic-title first"><strong>Chapters contents</strong></p>
<ul class="simple">
<li><a class="reference internal" href="#loading-data" id="id2">Loading data</a></li>
<li><a class="reference internal" href="#understanding-neuroimaging-data" id="id3">Understanding neuroimaging data</a></li>
<li><a class="reference internal" href="#masking-data-manually" id="id4">Masking data manually</a></li>
<li><a class="reference internal" href="#functions-for-data-preparation-steps" id="id5">Functions for data preparation steps</a></li>
<li><a class="reference internal" href="#image-operations-creating-a-roi-mask-manually" id="id6">Image operations: creating a ROI mask manually</a></li>
</ul>
</div>
<div class="section" id="loading-data">
<span id="id1"></span><h2><a class="toc-backref" href="#id2">5.2.1. Loading data</a><a class="headerlink" href="#loading-data" title="Permalink to this headline">¶</a></h2>
<div class="section" id="fetching-open-datasets">
<span id="datasets"></span><h3>5.2.1.1. Fetching open datasets<a class="headerlink" href="#fetching-open-datasets" title="Permalink to this headline">¶</a></h3>
<p>The nilearn package provides a dataset fetching utility that
automatically downloads reference
datasets and atlases. Dataset fetching functions can be imported from
<a class="reference internal" href="../modules/reference.html#module-nilearn.datasets" title="nilearn.datasets"><tt class="xref py py-mod docutils literal"><span class="pre">nilearn.datasets</span></tt></a>:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">nilearn</span> <span class="kn">import</span> <span class="n">datasets</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">haxby_dataset</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">fetch_haxby</span><span class="p">(</span><span class="n">n_subjects</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  
</pre></div>
</div>
<p>They return a data structure that contains different pieces of
information on the retrieved dataset, including the
file names on hard disk:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="c"># The different files</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">(</span><span class="nb">sorted</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">haxby_dataset</span><span class="o">.</span><span class="n">keys</span><span class="p">())))</span>  
<span class="go">[&#39;anat&#39;, &#39;description&#39;, &#39;func&#39;, &#39;mask&#39;, &#39;mask_face&#39;, &#39;mask_face_little&#39;,</span>
<span class="go">&#39;mask_house&#39;, &#39;mask_house_little&#39;, &#39;mask_vt&#39;, &#39;session_target&#39;]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c"># Path to first functional file</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">(</span><span class="n">haxby_dataset</span><span class="o">.</span><span class="n">func</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>  
<span class="go">/.../nilearn_data/haxby2001/subj1/bold.nii.gz</span>
</pre></div>
</div>
<p>Explanation and further resources of the dataset at hand can be retrieved as
follows:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">(</span><span class="n">haxby_dataset</span><span class="o">.</span><span class="n">description</span><span class="p">)</span>  
<span class="go">Haxby 2001 results</span>


<span class="go">Notes</span>
<span class="go">-----</span>
<span class="go">Results from a classical fMRI study that...</span>
</pre></div>
</div>
<div class="line-block">
<div class="line"><br /></div>
</div>
<p>For a list of all the data fetching functions in nilearn, see <a class="reference internal" href="../modules/reference.html#datasets-ref"><em>nilearn.datasets: Automatic Dataset Fetching</em></a>.</p>
<p>Besides convenient downloading of openly accessible reference datasets
including important meta-data (e.g., stimulus characteristics and
participant information for confound removal), the fetching functions
perform data downloads only once and return the locally saved data upon
any later function calls.
The locally stored data can be found in one of the
following directories (in order of priority, if present):</p>
<blockquote>
<div><ul class="simple">
<li>default system paths used by third party software that may already
provide the data (e.g., the Harvard-Oxford atlas
is provided by the FSL software suite)</li>
<li>the folder specified by <cite>data_dir</cite> parameter in the fetching function</li>
<li>the global environment variable <cite>NILEARN_SHARED_DATA</cite></li>
<li>the user environment variable <cite>NILEARN_DATA</cite></li>
<li>the <cite>nilearn_data</cite> folder in the user home folder</li>
</ul>
</div></blockquote>
<p>Two different environment variables are provided to distinguish a global dataset
repository that may be read-only at the user-level.
Note that you can copy that folder to another user&#8217;s computers to avoid
the initial dataset download on the first fetching call.</p>
</div>
<div class="section" id="loading-your-own-data">
<h3>5.2.1.2. Loading your own data<a class="headerlink" href="#loading-your-own-data" title="Permalink to this headline">¶</a></h3>
<p>Using your own data images in nilearn is as simple as creating a list of
file name strings</p>
<div class="highlight-python"><div class="highlight"><pre><span class="c"># dataset folder contains subject1.nii and subject2.nii</span>
<span class="n">my_data</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;dataset/subject1.nii&#39;</span><span class="p">,</span> <span class="s">&#39;dataset/subject2.nii&#39;</span><span class="p">]</span>
</pre></div>
</div>
<p>Nilearn also provides a &#8220;wildcard&#8221; pattern to list many files with one
expression:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="c"># dataset folder contains subject_01.nii to subject_03.nii</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c"># dataset/subject_*.nii is a glob expression matching all filenames.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c"># Example with a smoothing process:</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">nilearn.image</span> <span class="kn">import</span> <span class="n">smooth_img</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result_img</span> <span class="o">=</span> <span class="n">smooth_img</span><span class="p">(</span><span class="s">&quot;dataset/subject_*&quot;</span><span class="p">)</span> 
</pre></div>
</div>
<div class="topic">
<p class="topic-title first"><strong>Python globbing</strong></p>
<p>For more complicated use cases, Python also provides functions to work
with file paths, in particular, <a class="reference external" href="http://docs.python.org/2.7/library/glob.html#glob.glob" title="(in Python v2.7)"><tt class="xref py py-func docutils literal"><span class="pre">glob.glob</span></tt></a>.</p>
<div class="admonition warning">
<p class="first admonition-title">Warning</p>
<p class="last">Unlike nilearn&#8217;s path expansion, the result of <a class="reference external" href="http://docs.python.org/2.7/library/glob.html#glob.glob" title="(in Python v2.7)"><tt class="xref py py-func docutils literal"><span class="pre">glob.glob</span></tt></a> is
not sorted and depending on the computer you are running they
might not be in alphabetic order. We advise you to rely on
nilearn&#8217;s path expansion.</p>
</div>
</div>
</div>
</div>
<div class="section" id="understanding-neuroimaging-data">
<h2><a class="toc-backref" href="#id3">5.2.2. Understanding neuroimaging data</a><a class="headerlink" href="#understanding-neuroimaging-data" title="Permalink to this headline">¶</a></h2>
<div class="section" id="nifti-and-analyze-files">
<h3>5.2.2.1. Nifti and Analyze files<a class="headerlink" href="#nifti-and-analyze-files" title="Permalink to this headline">¶</a></h3>
<div class="topic">
<p class="topic-title first"><strong>NIfTI and Analyze file structures</strong></p>
<p><a class="reference external" href="http://nifti.nimh.nih.gov/">NifTi</a> files (or Analyze files) are
the standard way of sharing data in neuroimaging research.
Three main components are:</p>
<blockquote>
<div><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">data:</th><td class="field-body">raw scans in form of a numpy array: <tt class="docutils literal"><span class="pre">data</span> <span class="pre">=</span> <span class="pre">img.get_data()</span></tt></td>
</tr>
<tr class="field-even field"><th class="field-name">affine:</th><td class="field-body">returns the transformation matrix that maps
from voxel indices of the numpy array to actual real-world
locations of the brain:
<tt class="docutils literal"><span class="pre">affine</span> <span class="pre">=</span> <span class="pre">img.get_affine()</span></tt></td>
</tr>
<tr class="field-odd field"><th class="field-name">header:</th><td class="field-body">low-level informations about the data (slice duration, etc.):
<tt class="docutils literal"><span class="pre">header</span> <span class="pre">=</span> <span class="pre">img.get_header()</span></tt></td>
</tr>
</tbody>
</table>
</div></blockquote>
</div>
<p>Neuroimaging data can be loaded in a simple way thanks to <a class="reference external" href="http://nipy.sourceforge.net/nibabel/">nibabel</a>.
A Nifti file on disk can be loaded with a single line.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">nilearn</span> <span class="kn">import</span> <span class="n">datasets</span>

<span class="n">haxby_dataset</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">fetch_haxby</span><span class="p">(</span><span class="n">n_subjects</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c"># print basic information on the dataset</span>
<span class="k">print</span><span class="p">(</span><span class="s">&#39;First anatomical nifti image (3D) located is at: </span><span class="si">%s</span><span class="s">&#39;</span> <span class="o">%</span>
      <span class="n">haxby_dataset</span><span class="o">.</span><span class="n">anat</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="s">&#39;First functional nifti image (4D) is located at: </span><span class="si">%s</span><span class="s">&#39;</span> <span class="o">%</span>
      <span class="n">haxby_dataset</span><span class="o">.</span><span class="n">func</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

<span class="c">##############################################################################</span>
</pre></div>
</div>
<div class="topic">
<p class="topic-title first"><strong>Dataset formatting: data shape</strong></p>
<p>It is important to appreciate two main representations for
storing and accessing more than one Nifti images, that is sets
of MRI scans:</p>
<ul class="simple">
<li>a big 4D matrix representing (3D MRI + 1D for time), stored in a single
Nifti file.
<a class="reference external" href="http://www.fmrib.ox.ac.uk/fsl/">FSL</a> users tend to
prefer this format.</li>
<li>several 3D matrices representing each time point (single 3D volume) of the
session, stored in set of 3D Nifti or analyse files.
<a class="reference external" href="http://www.fil.ion.ucl.ac.uk/spm/">SPM</a> users tend
to prefer this format.</li>
</ul>
</div>
</div>
<div class="section" id="niimg-like-objects">
<span id="niimg"></span><h3>5.2.2.2. Niimg-like objects<a class="headerlink" href="#niimg-like-objects" title="Permalink to this headline">¶</a></h3>
<p>As a baseline, nilearn functions take as input argument what we call
&#8220;Niimg-like objects&#8221;:</p>
<p><strong>Niimg:</strong> A Niimg-like object can be one of the following:</p>
<blockquote>
<div><ul class="simple">
<li>A string variable with a file path to a Nifti or Analyse image</li>
<li>Any object exposing <tt class="docutils literal"><span class="pre">get_data()</span></tt> and <tt class="docutils literal"><span class="pre">get_affine()</span></tt> methods, typically
a <tt class="docutils literal"><span class="pre">Nifti1Image</span></tt> from <a class="reference external" href="http://nipy.sourceforge.net/nibabel/">nibabel</a>.</li>
</ul>
</div></blockquote>
<p><strong>Niimg-4D:</strong> Similarly, some functions require 4D Nifti-like
data, which we call Niimgs or Niimg-4D. Accepted input arguments are:</p>
<blockquote>
<div><ul class="simple">
<li>A path to a 4D Nifti image</li>
<li>List of paths to 3D Nifti images</li>
<li>4D Nifti-like object</li>
<li>List of 3D Nifti-like objects</li>
</ul>
</div></blockquote>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p><strong>Image affines</strong></p>
<p class="last">If you provide a sequence of Nifti images, all of them must have the same
affine.</p>
</div>
</div>
<div class="section" id="text-files-phenotype-or-behavior">
<h3>5.2.2.3. Text files: phenotype or behavior<a class="headerlink" href="#text-files-phenotype-or-behavior" title="Permalink to this headline">¶</a></h3>
<p>Phenotypic or behavioral data are often provided as text or CSV
(Comma Separated Values) file. They
can be loaded with <cite>numpy.genfromtxt</cite> but you may have to specify some options
(typically <cite>skip_header</cite> ignores column titles if needed).</p>
<p>For the Haxby datasets, we can load the categories of the images
presented to the subject:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">nilearn</span> <span class="kn">import</span> <span class="n">datasets</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">haxby_dataset</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">fetch_haxby</span><span class="p">(</span><span class="n">n_subjects</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">recfromcsv</span><span class="p">(</span><span class="n">haxby_dataset</span><span class="o">.</span><span class="n">session_target</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">delimiter</span><span class="o">=</span><span class="s">&quot; &quot;</span><span class="p">)</span>  
<span class="gp">&gt;&gt;&gt; </span><span class="n">stimuli</span> <span class="o">=</span> <span class="n">labels</span><span class="p">[</span><span class="s">&#39;labels&#39;</span><span class="p">]</span>  
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">stimuli</span><span class="p">))</span>  
<span class="go">[&#39;bottle&#39; &#39;cat&#39; &#39;chair&#39; &#39;face&#39; &#39;house&#39; &#39;rest&#39; &#39;scissors&#39; &#39;scrambledpix&#39;</span>
<span class="go"> &#39;shoe&#39;]</span>
</pre></div>
</div>
<div class="line-block">
<div class="line"><br /></div>
</div>
</div>
</div>
<div class="section" id="masking-data-manually">
<h2><a class="toc-backref" href="#id4">5.2.3. Masking data manually</a><a class="headerlink" href="#masking-data-manually" title="Permalink to this headline">¶</a></h2>
<div class="section" id="extracting-a-brain-mask">
<h3>5.2.3.1. Extracting a brain mask<a class="headerlink" href="#extracting-a-brain-mask" title="Permalink to this headline">¶</a></h3>
<p>If we do not have a spatial mask of the target regions, a brain mask
can be easily extracted from the fMRI data by the
<a class="reference internal" href="../modules/generated/nilearn.masking.compute_epi_mask.html#nilearn.masking.compute_epi_mask" title="nilearn.masking.compute_epi_mask"><tt class="xref py py-func docutils literal"><span class="pre">nilearn.masking.compute_epi_mask</span></tt></a> function:</p>
<div class="figure align-right">
<a class="reference external image-reference" href="../auto_examples/01_plotting/plot_visualization.html"><img alt="../_images/sphx_glr_plot_visualization_0021.png" src="../_images/sphx_glr_plot_visualization_0021.png" style="width: 330.0px; height: 130.0px;" /></a>
</div>
<div class="highlight-python"><div class="highlight"><pre><span class="c"># Simple computation of a mask from the fMRI data</span>
<span class="kn">from</span> <span class="nn">nilearn.masking</span> <span class="kn">import</span> <span class="n">compute_epi_mask</span>
<span class="n">mask_img</span> <span class="o">=</span> <span class="n">compute_epi_mask</span><span class="p">(</span><span class="n">func_filename</span><span class="p">)</span>

<span class="c"># Visualize it as an ROI</span>
<span class="kn">from</span> <span class="nn">nilearn.plotting</span> <span class="kn">import</span> <span class="n">plot_roi</span>
<span class="n">plot_roi</span><span class="p">(</span><span class="n">mask_img</span><span class="p">,</span> <span class="n">mean_haxby</span><span class="p">)</span>

<span class="c">##############################################################################</span>
</pre></div>
</div>
</div>
<div class="section" id="from-4d-nifti-images-to-2d-data-arrays">
<span id="mask-4d-2-3d"></span><h3>5.2.3.2. From 4D Nifti images to 2D data arrays<a class="headerlink" href="#from-4d-nifti-images-to-2d-data-arrays" title="Permalink to this headline">¶</a></h3>
<p>fMRI data is usually represented as a 4D block of data: 3 spatial
dimensions and one time dimension. In practice, we are usually
interested in working on the voxel time-series in the
brain. It is thus convenient to apply a brain mask in order to convert the
4D brain images representation into a restructured 2D data representation,
<cite>voxel</cite> <strong>x</strong> <cite>time</cite>, as depicted below:</p>
<a class="reference internal image-reference" href="../_images/masking.jpg"><img alt="../_images/masking.jpg" class="align-center" src="../_images/masking.jpg" style="width: 100%;" /></a>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">nilearn.masking</span> <span class="kn">import</span> <span class="n">apply_mask</span>
<span class="n">masked_data</span> <span class="o">=</span> <span class="n">apply_mask</span><span class="p">(</span><span class="n">func_filename</span><span class="p">,</span> <span class="n">mask_img</span><span class="p">)</span>

<span class="c"># masked_data shape is (timepoints, voxels). We can plot the first 150</span>
<span class="c"># timepoints from two voxels</span>

<span class="c"># And now plot a few of these</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">masked_data</span><span class="p">[:</span><span class="mi">2</span><span class="p">,</span> <span class="p">:</span><span class="mi">150</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">&#39;Time [TRs]&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">&#39;Intensity&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">150</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">bottom</span><span class="o">=.</span><span class="mi">12</span><span class="p">,</span> <span class="n">top</span><span class="o">=.</span><span class="mi">95</span><span class="p">,</span> <span class="n">right</span><span class="o">=.</span><span class="mi">95</span><span class="p">,</span> <span class="n">left</span><span class="o">=.</span><span class="mi">12</span><span class="p">)</span>

<span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<div class="figure align-center">
<a class="reference external image-reference" href="../auto_examples/01_plotting/plot_visualization.html"><img alt="../_images/sphx_glr_plot_visualization_0031.png" src="../_images/sphx_glr_plot_visualization_0031.png" style="width: 350.0px; height: 250.0px;" /></a>
</div>
</div>
</div>
<div class="section" id="functions-for-data-preparation-steps">
<span id="preprocessing-functions"></span><h2><a class="toc-backref" href="#id5">5.2.4. Functions for data preparation steps</a><a class="headerlink" href="#functions-for-data-preparation-steps" title="Permalink to this headline">¶</a></h2>
<p>The <a class="reference internal" href="../modules/generated/nilearn.input_data.NiftiMasker.html#nilearn.input_data.NiftiMasker" title="nilearn.input_data.NiftiMasker"><tt class="xref py py-class docutils literal"><span class="pre">NiftiMasker</span></tt></a> can automatically perform important data preparation
steps. These steps are also available as independent functions if you want to
set up your own data preparation procedure:</p>
<ul class="simple">
<li>Resampling: <a class="reference internal" href="../modules/generated/nilearn.image.resample_img.html#nilearn.image.resample_img" title="nilearn.image.resample_img"><tt class="xref py py-func docutils literal"><span class="pre">nilearn.image.resample_img</span></tt></a>. See the example
<a class="reference internal" href="../auto_examples/04_manipulating_images/plot_affine_transformation.html#sphx-glr-auto-examples-04-manipulating-images-plot-affine-transformation-py"><em>Visualization of affine resamplings</em></a> to
see the effect of affine transforms on data and bounding boxes.</li>
<li>Computing the mean of images (along the time/4th dimension):
<a class="reference internal" href="../modules/generated/nilearn.image.mean_img.html#nilearn.image.mean_img" title="nilearn.image.mean_img"><tt class="xref py py-func docutils literal"><span class="pre">nilearn.image.mean_img</span></tt></a></li>
<li>Applying numpy functions on an image or a list of images:
<a class="reference internal" href="../modules/generated/nilearn.image.math_img.html#nilearn.image.math_img" title="nilearn.image.math_img"><tt class="xref py py-func docutils literal"><span class="pre">nilearn.image.math_img</span></tt></a></li>
<li>Swapping voxels of both hemisphere (e.g., useful to homogenize masks
inter-hemispherically):
<a class="reference internal" href="../modules/generated/nilearn.image.swap_img_hemispheres.html#nilearn.image.swap_img_hemispheres" title="nilearn.image.swap_img_hemispheres"><tt class="xref py py-func docutils literal"><span class="pre">nilearn.image.swap_img_hemispheres</span></tt></a></li>
<li>Smoothing: <a class="reference internal" href="../modules/generated/nilearn.image.smooth_img.html#nilearn.image.smooth_img" title="nilearn.image.smooth_img"><tt class="xref py py-func docutils literal"><span class="pre">nilearn.image.smooth_img</span></tt></a></li>
<li>Masking:<ul>
<li>compute from EPI images: <a class="reference internal" href="../modules/generated/nilearn.masking.compute_epi_mask.html#nilearn.masking.compute_epi_mask" title="nilearn.masking.compute_epi_mask"><tt class="xref py py-func docutils literal"><span class="pre">nilearn.masking.compute_epi_mask</span></tt></a></li>
<li>compute from images with a flat background:
<a class="reference internal" href="../modules/generated/nilearn.masking.compute_background_mask.html#nilearn.masking.compute_background_mask" title="nilearn.masking.compute_background_mask"><tt class="xref py py-func docutils literal"><span class="pre">nilearn.masking.compute_background_mask</span></tt></a></li>
<li>compute for multiple sessions/subjects:
<a class="reference internal" href="../modules/generated/nilearn.masking.compute_multi_epi_mask.html#nilearn.masking.compute_multi_epi_mask" title="nilearn.masking.compute_multi_epi_mask"><tt class="xref py py-func docutils literal"><span class="pre">nilearn.masking.compute_multi_epi_mask</span></tt></a>
<a class="reference internal" href="../modules/generated/nilearn.masking.compute_multi_background_mask.html#nilearn.masking.compute_multi_background_mask" title="nilearn.masking.compute_multi_background_mask"><tt class="xref py py-func docutils literal"><span class="pre">nilearn.masking.compute_multi_background_mask</span></tt></a></li>
<li>apply: <a class="reference internal" href="../modules/generated/nilearn.masking.apply_mask.html#nilearn.masking.apply_mask" title="nilearn.masking.apply_mask"><tt class="xref py py-func docutils literal"><span class="pre">nilearn.masking.apply_mask</span></tt></a></li>
<li>intersect several masks (useful for multi sessions/subjects): <a class="reference internal" href="../modules/generated/nilearn.masking.intersect_masks.html#nilearn.masking.intersect_masks" title="nilearn.masking.intersect_masks"><tt class="xref py py-func docutils literal"><span class="pre">nilearn.masking.intersect_masks</span></tt></a></li>
<li>unmasking: <a class="reference internal" href="../modules/generated/nilearn.masking.unmask.html#nilearn.masking.unmask" title="nilearn.masking.unmask"><tt class="xref py py-func docutils literal"><span class="pre">nilearn.masking.unmask</span></tt></a></li>
</ul>
</li>
<li>Cleaning signals (e.g., linear detrending, standardization,
confound removal, low/high pass filtering): <a class="reference internal" href="../modules/generated/nilearn.signal.clean.html#nilearn.signal.clean" title="nilearn.signal.clean"><tt class="xref py py-func docutils literal"><span class="pre">nilearn.signal.clean</span></tt></a></li>
</ul>
</div>
<div class="section" id="image-operations-creating-a-roi-mask-manually">
<h2><a class="toc-backref" href="#id6">5.2.5. Image operations: creating a ROI mask manually</a><a class="headerlink" href="#image-operations-creating-a-roi-mask-manually" title="Permalink to this headline">¶</a></h2>
<p>This section shows manual steps to create and further modify a ROI
(region of interest) spatial mask. They represent a means for &#8220;data folding&#8221;,
that is, extracting and later analyzing data from a subset of voxels rather
than the entire brain images. As a convenient side effect, this can help
alleviate the curse of dimensionality (i.e., statistical problems that
arise in the context of high-dimensional input variables).</p>
<div class="section" id="smoothing">
<h3>5.2.5.1. Smoothing<a class="headerlink" href="#smoothing" title="Permalink to this headline">¶</a></h3>
<p>Functional MRI data have a low signal-to-noise ratio (yet much better
than EEG or MEG measurements).
When using simple methods
that are not robust to noise, it is useful to apply a spatial filtering
kernel on the data. Such data smoothing is
usually applied using a Gaussian function with 4mm to 12mm full-width at
half-maximum (this is where the FWHM comes from).
The function <a class="reference internal" href="../modules/generated/nilearn.image.smooth_img.html#nilearn.image.smooth_img" title="nilearn.image.smooth_img"><tt class="xref py py-func docutils literal"><span class="pre">nilearn.image.smooth_img</span></tt></a> accounts for potential
anisotropy in the image affine (i.e., non-identical voxel size in all
the three dimensions). Analogous to the majority of nilearn functions,
it can also use file names as input parameters.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">nilearn</span> <span class="kn">import</span> <span class="n">image</span>
<span class="n">fmri_filename</span> <span class="o">=</span> <span class="n">haxby_dataset</span><span class="o">.</span><span class="n">func</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">fmri_img</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">smooth_img</span><span class="p">(</span><span class="n">fmri_filename</span><span class="p">,</span> <span class="n">fwhm</span><span class="o">=</span><span class="mi">6</span><span class="p">)</span>

<span class="c"># Plot the mean image</span>
<span class="kn">from</span> <span class="nn">nilearn.plotting</span> <span class="kn">import</span> <span class="n">plot_epi</span>
<span class="n">mean_img</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">mean_img</span><span class="p">(</span><span class="n">fmri_img</span><span class="p">)</span>
<span class="n">plot_epi</span><span class="p">(</span><span class="n">mean_img</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s">&#39;Smoothed mean EPI&#39;</span><span class="p">,</span> <span class="n">cut_coords</span><span class="o">=</span><span class="n">cut_coords</span><span class="p">)</span>

<span class="c">##############################################################################</span>
</pre></div>
</div>
<div class="figure align-center">
<a class="reference external image-reference" href="../auto_examples/04_manipulating_images/plot_roi_extraction.html"><img alt="../_images/sphx_glr_plot_roi_extraction_0011.png" src="../_images/sphx_glr_plot_roi_extraction_0011.png" style="width: 330.0px; height: 130.0px;" /></a>
</div>
</div>
<div class="section" id="selecting-features">
<h3>5.2.5.2. Selecting features<a class="headerlink" href="#selecting-features" title="Permalink to this headline">¶</a></h3>
<p>Functional MRI data can be considered &#8220;high dimensional&#8221; given the
p-versus-n ratio (e.g., p=~50,000-200,000 voxels for n=1000 samples).
In this setting, machine-learning
algorithms can perform poorly (i.e., curse-of-dimensionality problem).
However, simple means from the realms of classical statistics can help
reducing the number of voxels.</p>
<p>The Student&#8217;s t-test (<a class="reference external" href="http://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html#scipy.stats.ttest_ind" title="(in SciPy v0.17.0)"><tt class="xref py py-func docutils literal"><span class="pre">scipy.stats.ttest_ind</span></tt></a>) is an established
method to determine whether two
distributions are statistically different. It can be used to compare voxel
time-series from two different experimental conditions
(e.g., when houses or faces are shown to individuals during brain scanning).
If the time-series distribution is similar in the two conditions, then the
voxel is not very interesting to discriminate the condition.</p>
<p>This test returns p-values that represent probabilities that the two
time-series had been drawn from the same distribution. The lower is the p-value, the
more discriminative is the voxel in distinguishing the two conditions.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">stats</span>
<span class="n">fmri_data</span> <span class="o">=</span> <span class="n">fmri_img</span><span class="o">.</span><span class="n">get_data</span><span class="p">()</span>
<span class="n">_</span><span class="p">,</span> <span class="n">p_values</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">ttest_ind</span><span class="p">(</span><span class="n">fmri_data</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">haxby_labels</span> <span class="o">==</span> <span class="n">b</span><span class="s">&#39;face&#39;</span><span class="p">],</span>
                              <span class="n">fmri_data</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">haxby_labels</span> <span class="o">==</span> <span class="n">b</span><span class="s">&#39;house&#39;</span><span class="p">],</span>
                              <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

<span class="c"># Use a log scale for p-values</span>
<span class="n">log_p_values</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">log10</span><span class="p">(</span><span class="n">p_values</span><span class="p">)</span>
<span class="n">log_p_values</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">log_p_values</span><span class="p">)]</span> <span class="o">=</span> <span class="mf">0.</span>
<span class="n">log_p_values</span><span class="p">[</span><span class="n">log_p_values</span> <span class="o">&gt;</span> <span class="mf">10.</span><span class="p">]</span> <span class="o">=</span> <span class="mf">10.</span>
<span class="kn">from</span> <span class="nn">nilearn.plotting</span> <span class="kn">import</span> <span class="n">plot_stat_map</span>
<span class="n">plot_stat_map</span><span class="p">(</span><span class="n">new_img_like</span><span class="p">(</span><span class="n">fmri_img</span><span class="p">,</span> <span class="n">log_p_values</span><span class="p">),</span>
              <span class="n">mean_img</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s">&quot;p-values&quot;</span><span class="p">,</span> <span class="n">cut_coords</span><span class="o">=</span><span class="n">cut_coords</span><span class="p">)</span>

<span class="c">##############################################################################</span>
</pre></div>
</div>
<div class="figure align-center">
<a class="reference external image-reference" href="../auto_examples/04_manipulating_images/plot_roi_extraction.html"><img alt="../_images/sphx_glr_plot_roi_extraction_0021.png" src="../_images/sphx_glr_plot_roi_extraction_0021.png" style="width: 365.0px; height: 130.0px;" /></a>
</div>
<p>This feature selection method is available in the scikit-learn Python
package, where it has been
extended to several classes, using the
<a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.f_classif.html#sklearn.feature_selection.f_classif" title="(in scikit-learn v0.17.1)"><tt class="xref py py-func docutils literal"><span class="pre">sklearn.feature_selection.f_classif</span></tt></a> function.</p>
</div>
<div class="section" id="thresholding">
<h3>5.2.5.3. Thresholding<a class="headerlink" href="#thresholding" title="Permalink to this headline">¶</a></h3>
<p>Voxels with better p-values are kept as voxels of interest.
Applying a threshold to an array
is easy thanks to numpy indexing à la Matlab.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">log_p_values</span><span class="p">[</span><span class="n">log_p_values</span> <span class="o">&lt;</span> <span class="mi">5</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">plot_stat_map</span><span class="p">(</span><span class="n">new_img_like</span><span class="p">(</span><span class="n">fmri_img</span><span class="p">,</span> <span class="n">log_p_values</span><span class="p">),</span>
              <span class="n">mean_img</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s">&#39;Thresholded p-values&#39;</span><span class="p">,</span> <span class="n">annotate</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
              <span class="n">colorbar</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">cut_coords</span><span class="o">=</span><span class="n">cut_coords</span><span class="p">)</span>

<span class="c">##############################################################################</span>
</pre></div>
</div>
<div class="figure align-center">
<a class="reference external image-reference" href="../auto_examples/04_manipulating_images/plot_roi_extraction.html"><img alt="../_images/sphx_glr_plot_roi_extraction_0031.png" src="../_images/sphx_glr_plot_roi_extraction_0031.png" style="width: 330.0px; height: 130.0px;" /></a>
</div>
</div>
<div class="section" id="mask-intersection">
<h3>5.2.5.4. Mask intersection<a class="headerlink" href="#mask-intersection" title="Permalink to this headline">¶</a></h3>
<p>We now want to restrict our investigation to the ventral temporal area. The
corresponding spatial mask is provided in <cite>haxby.mask_vt</cite>.
We want to compute the
intersection of this provided mask with our self-computed mask.
The first step is to load it with
nibabel&#8217;s <strong>nibabel.load</strong>. We can then use a logical &#8220;and&#8221; operation
&#8211; <strong>numpy.logical_and</strong> &#8211; to keep only voxels
that have been selected in both masks. In neuroimaging jargon, this is
called an &#8220;AND conjunction.&#8221;</p>
<div class="highlight-python"><div class="highlight"><pre><span class="c"># (intersection corresponds to an &quot;AND conjunction&quot;)</span>
<span class="n">bin_p_values</span> <span class="o">=</span> <span class="p">(</span><span class="n">log_p_values</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">mask_vt_filename</span> <span class="o">=</span> <span class="n">haxby_dataset</span><span class="o">.</span><span class="n">mask_vt</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="kn">import</span> <span class="nn">nibabel</span>
<span class="n">vt</span> <span class="o">=</span> <span class="n">nibabel</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">mask_vt_filename</span><span class="p">)</span><span class="o">.</span><span class="n">get_data</span><span class="p">()</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">bool</span><span class="p">)</span>
<span class="n">bin_p_values_and_vt</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">logical_and</span><span class="p">(</span><span class="n">bin_p_values</span><span class="p">,</span> <span class="n">vt</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">nilearn.plotting</span> <span class="kn">import</span> <span class="n">plot_roi</span><span class="p">,</span> <span class="n">show</span>
<span class="n">plot_roi</span><span class="p">(</span><span class="n">new_img_like</span><span class="p">(</span><span class="n">fmri_img</span><span class="p">,</span> <span class="n">bin_p_values_and_vt</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int</span><span class="p">)),</span>
         <span class="n">mean_img</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s">&#39;Intersection with ventral temporal mask&#39;</span><span class="p">,</span>
         <span class="n">cut_coords</span><span class="o">=</span><span class="n">cut_coords</span><span class="p">)</span>

<span class="c">##############################################################################</span>
</pre></div>
</div>
<div class="figure align-center">
<a class="reference external image-reference" href="../auto_examples/04_manipulating_images/plot_roi_extraction.html"><img alt="../_images/sphx_glr_plot_roi_extraction_0041.png" src="../_images/sphx_glr_plot_roi_extraction_0041.png" style="width: 330.0px; height: 130.0px;" /></a>
</div>
</div>
<div class="section" id="mask-dilation">
<h3>5.2.5.5. Mask dilation<a class="headerlink" href="#mask-dilation" title="Permalink to this headline">¶</a></h3>
<p>Tresholded functional brain images often contain scattered voxels
across the brain.
To consolidate such brain images towards more
compact shapes, we use a <a class="reference external" href="http://en.wikipedia.org/wiki/Dilation_(morphology)">morphological dilation</a>. This is a common step to be sure
not to forget voxels located on the edge of a ROI.
Put differently, such operations can fill &#8220;holes&#8221; in masked voxel
representations.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">ndimage</span>
<span class="n">dil_bin_p_values_and_vt</span> <span class="o">=</span> <span class="n">ndimage</span><span class="o">.</span><span class="n">binary_dilation</span><span class="p">(</span><span class="n">bin_p_values_and_vt</span><span class="p">)</span>
<span class="n">plot_roi</span><span class="p">(</span><span class="n">new_img_like</span><span class="p">(</span><span class="n">fmri_img</span><span class="p">,</span> <span class="n">dil_bin_p_values_and_vt</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int</span><span class="p">)),</span>
         <span class="n">mean_img</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s">&#39;Dilated mask&#39;</span><span class="p">,</span> <span class="n">cut_coords</span><span class="o">=</span><span class="n">cut_coords</span><span class="p">,</span>
         <span class="n">annotate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>


<span class="c">##############################################################################</span>
</pre></div>
</div>
<div class="figure align-center">
<a class="reference external image-reference" href="../auto_examples/04_manipulating_images/plot_roi_extraction.html"><img alt="../_images/sphx_glr_plot_roi_extraction_0051.png" src="../_images/sphx_glr_plot_roi_extraction_0051.png" style="width: 330.0px; height: 130.0px;" /></a>
</div>
</div>
<div class="section" id="extracting-connected-components">
<h3>5.2.5.6. Extracting connected components<a class="headerlink" href="#extracting-connected-components" title="Permalink to this headline">¶</a></h3>
<p>The function <strong>scipy.ndimage.label</strong> from the scipy Python library
identifies immediately neighboring
voxels in our voxels mask. It assigns a separate integer label to each
one of them.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">labels</span><span class="p">,</span> <span class="n">n_labels</span> <span class="o">=</span> <span class="n">ndimage</span><span class="o">.</span><span class="n">label</span><span class="p">(</span><span class="n">dil_bin_p_values_and_vt</span><span class="p">)</span>
<span class="n">first_roi_data</span> <span class="o">=</span> <span class="p">(</span><span class="n">labels</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int</span><span class="p">)</span>
<span class="n">second_roi_data</span> <span class="o">=</span> <span class="p">(</span><span class="n">labels</span> <span class="o">==</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int</span><span class="p">)</span>
<span class="n">plot_roi</span><span class="p">(</span><span class="n">new_img_like</span><span class="p">(</span><span class="n">fmri_img</span><span class="p">,</span> <span class="n">first_roi_data</span><span class="p">),</span>
         <span class="n">mean_img</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s">&#39;Connected components: first ROI&#39;</span><span class="p">)</span>

<span class="n">plot_roi</span><span class="p">(</span><span class="n">new_img_like</span><span class="p">(</span><span class="n">fmri_img</span><span class="p">,</span> <span class="n">second_roi_data</span><span class="p">),</span>
         <span class="n">mean_img</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s">&#39;Connected components: second ROI&#39;</span><span class="p">)</span>


<span class="c">##############################################################################</span>
</pre></div>
</div>
<div class="figure align-center">
<a class="reference external image-reference" href="../auto_examples/04_manipulating_images/plot_roi_extraction.html"><img alt="../_images/sphx_glr_plot_roi_extraction_0061.png" src="../_images/sphx_glr_plot_roi_extraction_0061.png" style="width: 330.0px; height: 130.0px;" /></a>
</div>
</div>
<div class="section" id="saving-the-result">
<h3>5.2.5.7. Saving the result<a class="headerlink" href="#saving-the-result" title="Permalink to this headline">¶</a></h3>
<p>The final voxel mask is saved using nibabel for further inspection
with a software such as FSLView.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">nibabel</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">new_img_like</span><span class="p">(</span><span class="n">fmri_img</span><span class="p">,</span> <span class="n">labels</span><span class="p">),</span>
             <span class="s">&#39;mask_atlas.nii&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../building_blocks/index.html" title="6. Advanced usage: manual pipelines and scaling up"
             >next</a></li>
        <li class="right" >
          <a href="data_preparation.html" title="5.1. Data preparation: loading and basic signal extraction"
             >previous</a> |</li>
<li><a href="../index.html">Nilearn Home</a> |&nbsp;</li>
<li><a href="../user_guide.html">User Guide</a> |&nbsp;</li>
<li><a href="../auto_examples/index.html">Examples</a> |&nbsp;</li>
<li><a href="../modules/reference.html">Reference</a> |&nbsp;</li>
<li id="navbar-about"><a href="../authors.html">About</a>|&nbsp;</li>
<li id="navbar-ecosystem"><a href="http://www.nipy.org/">Nipy ecosystem</a></li>

          <li><a href="../user_guide.html" >User guide: table of contents</a> &raquo;</li>
          <li><a href="index.html" >5. Image manipulation</a> &raquo;</li> 
      </ul>
    </div>
    <div class="footer">
            &copy; The nilearn developers 2010-2015.
          Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 1.2.2.
        <span style="padding-left: 5ex;">
          <a href="../_sources/manipulating_images/manipulating_images.txt"
        	 rel="nofollow">Show this page source</a>
        </span>
    </div>
  </body>
</html>